---
output:
   bookdown::html_document2
---

# Required Math Skills and Symbols {#ch.math}

In this chapter we introduce most of the mathematics and symbols that are used in the book. We start with the concept and sumbols for summation used to represent sums of many numbers generally and succintly. We use simple numerical examples for which we give the mathematical equations and the corresponding R code to perform the operations. In order to present the symbols in a context that is relevant for the rest of the book, we dive into equations for averages and variances, and we present models. At this point, the definitions of mean, variance, etc. and the formulation of specific models are not the main points, and they will be presented later in more detail.

A key point in this chapter is that in statistics we are always using models, and that making those models explicit by writing them down completely is essential to understanding and communicating what we are doing. The chapter develops a couple of models of increasing complexity and uses those to present the equations, symbols and mathematical concepts that are used throught the rest of the book.

A second key concept, related to the first one, is that we rarely, if ever, can know the actual "true" value of parameters, variables or quantities about the real world. We do not know paramter values because we rarely know or even have access to the whole population, which would be necesary to "measure" a parameter like the true mean. Measurements are imperfect because measuring instruments have limited precision, and because they are used by "imperfect" humans that make all sorts of errors. The imperfection of measurements should rarely be an issue for the topics covered in this course, and our focus is on estimation of unknown parameters. However, when dealing with chaotic systems, for example in weather forecasting, the imprecision of the measurements is a major limitation, because even minute errors in measurement grow exponentially over time. Although the physical properties of the atmosphere are well known, the imperfection of measurements prevent long-term prediction of specific weather with high confidence.

In reading this chapter, focus on the symbols and concepts. In addition to, and better before doing the exercises, students should make sure that they can reproduce the tables of symbols with subscripts, and the symbols for specific table elements and sums of elements. We recommend writing down the equations as they are read, and then trying to reproduce them from memory and a description of the calculation (e.g. sum of all moisture values for corn in fields 3 through 7). This will greatly facilitate the attention to the symbols and details of each equation, and will reveal those aspects that are were not yet clear to the reader.

## Learning Objectives for Chapter {#math.obj}

1. Identify and write down simple statistical models.
1. Read and interpret mathematical equations.
1. Identify random and fixed components of statistial models.
1. Pair symbols with corresponding concepts or definitions.
1. Express sums using summation symbol and expand sums defined with the summation symbol.
1. Calculate sum of squared deviations for a set of numbers.
1. Explain in your own words what the sum of squares of a set of numbers describes.  
1. Identify the symbols that correspond to standard deviation, variance, population mean, and sample average.
1. List the different strategies we can use to find the optimal value for an unknown variable.


## Data Columns and Summation {#math.sum}

Summations, the sum of several numbers that are organized with subscripts, is used all the time in statistics. In order to be able to read equations and understand the concepts in them, you have to be familiar with summations. The greek letter capital sigma $\Sigma$ is used to represent summation. For example, $\sum_{i=1}^{4} Y_i$ represents the sum $Y_1 + Y_2 + Y_3 + Y_4$. Sometimes, for simplicity, when we want to sum over all possible values of the subscript i from $i = 1$ to the maximum but unspecified value of $i = k$, we write $\sum_{i=1}^k Y_i$, meaning "sum of all values of $Y_i$."

We can write a symbol for all the $Y_i$ to avoid having to write each one of them. All the values of $Y$ in the correct order constitute a *vector* of values. We use bold letters to refer to vectors. Suppose we have a vector with the numbers 7, 5, 9 and 6. We write this as:

\begin{equation}
\mathbf{Y} = \begin{pmatrix} Y_1 & Y_2 & Y_3 & Y_4 \end{pmatrix} = \begin{pmatrix} 7 & 5 & 9 & 6 \end{pmatrix} = \left( Y_i \right) \quad i = 1, \dots, 4
(\#eq:math01)
\end{equation}


where it is impied that $Y_1 = 7$, $Y_2 = 5$, $Y_3 = 9$ and $Y_4 = 6$. There are no calculations or concepts here other than the fact that vectors are sets of numbers with order, and that we can refer to them with symbols. In R we can define the vector and give it values using the `c` function, which stands for "combine."

```{r}
Y <- c(7, 5, 9, 6)
print(Y)
# The "[1]" on the left simply indicates that 7 is the first element in the vector.
```

These summation equations have parallels in R code. In R, we put all values of Y in a vector, and the subscripts are automatically assigned or implicit based on the position of each value of Y. You can think of the vector being a column, so the positions of the vector elements are the row numbers.

We can refer to each element in Y by using its row number or index number inside brackets and right next to the name of the vector. For example, `Y[2]` is the second element of Y, which is the number 5. Using different expressions instead of a single number we can extract any parts of Y we need to operate with.

```{r}
# Extract the third element of Y
Y[3]
# The "[1]" on the left simply indicates that 3 is the first element 
# in the vector represented by the third element of Y.

# Extract elements 2 to 3 of Y
Y[2:3]
# The "[1]" on the left simply indicates that 5 is the first element 
# in the vector represented by the third and forth elements of Y.

# Extract elements 1, 3 and 4 of Y
Y[c(1, 3:4)]

```


Consider the following to get an idea of what the symbols mean and how they work.

\begin{equation} 
\sum\mathbf{Y} = \sum_{i=1}^{i=4} Y_i = Y_1 + Y_2 + Y_3 + Y_4 = 7 + 5 + 9 + 6 = 27
(\#eq:math02)
\end{equation} 

Because most R operations are vectorized, if we want to use the whole vector we do not need to specify subscripts, R takes `sum(Y)` to mean "sum all elements of Y." To sum parts of a vector we need to use the extraction method.

```{r}
sum(Y)
```

\begin{equation} 
\displaystyle\sum_{i=2}^{i=4} Y_i = Y_2 + Y_3 + Y_4 = 5 + 9 + 6 = 20
(\#eq:math03)
\end{equation} 

```{r}
sum(Y[2:4])
```

The subscripts for summations can themselves be equations, which makes these formulas very versatile, although in this course we will not be using many complicated subscripts.

\begin{equation} 
\displaystyle\sum_{i=1}^{i=3} Y_{i} = \displaystyle\sum_{i=2}^{i=4} Y_{i-1} = Y_1 + Y_2 + Y_3 = 7 + 5 + 9 = 21
(\#eq:math04)
\end{equation} 


\begin{equation} 
\begin{aligned}
\displaystyle\sum_{i=1}^{i=3} \left( Y_{i} + Y_{i+1} \right) &= \left( Y_1 + Y_2 \right) + \left( Y_2 + Y_3 \right) + \left( Y_3 + Y_4 \right) \\ &= 
Y_1 + Y_2 + Y_2 + Y_3 + Y_3 + Y_4 \\ \\ &= 
7 + 5 + 5 + 9 + 9 + 6 = 41
\end{aligned}
(\#eq:math05)
\end{equation} 

As usual, there are many ways to achieve a task in R. To perform the sum above we can use the following alternatives:

```{r}
sum(Y[1:3] + Y[2:4])
sum(Y[1:3]) + sum(Y[2:4])
i <- 1:3
sum(Y[i] + Y[i + 1])

```

In order to explain further properties of the summation, let's use a second vector represented by the letter $\mathbf{X}$, where

\begin{equation} 
\mathbf{X} = \begin{pmatrix} X_1 & X_2 & X_3 & X_4 \end{pmatrix} = \begin{pmatrix} 3 & 2 & 4 & 5 \end{pmatrix} = \left( X_i \right) \quad i = 1, \dots, 4
(\#eq:math06)
\end{equation} 

```{r}
X <- c(3, 2, 4, 5)
print(X)
```


The notation is very general and can be used to express sums like the following sum of products of corresponding elements in $\mathbf{X}$ and $\mathbf{Y}$:

\begin{equation} 
\begin{aligned}
\displaystyle\sum_{i=1}^{i=4} (X_{i} \ Y_{i}) 
&= (X_1 \ Y_1) + (X_2 \ Y_2) + (X_3 \ Y_3) + (X_4 \ Y_4) \\ &= 
3 \times 7 + 2 \times 5 + 4 \times 9 + 5 \times 6 = 97
\end{aligned}
(\#eq:math07)
\end{equation} 

## Two-dimensional Data Tables and Summation {#math.2Dtbl}

The vectors $\mathbf{X}$ and $\mathbf{Y}$ used above are 1-dimensional; they are single columns of numbers. Frequently, data is organized in more than one dimension, as in a 2-dimensional table with rows and columns. A conventional and very clear way to represent those tables is a matrix where each element is identified by its "address" in the table given by the row and column numbers, always in that order. The subscript $i$ refers to rows and $j$ refers to columns. We illustrate this with an example in which soil moisture was measured under wheat, corn and tomatoes in each of 7 fields (numbers are fictitious). The matrix is built by using rows for fields and columns for crops. Note that the subscripts are not numbers with 2 digits, but two single-digit integer written together; subscript 62 does **not** mean 6 times 10 plus 2 times 1, but simply the sixh row and second column. For situations when there are more than 9 rows and or columns, we use a separator between the row and column numbers to avoid ambiguity (for example, to be able to tell if $Y_{162}$ is row 1 column 62 or row 16 column 2 we use $Y_{1,62}$ or $Y_{16,2}$. The comma is ommitted when each subscript is never greater than 9.\
  \
  \
\begin{equation} 
\mathbf{Y} = 
 \begin{pmatrix}
  Y_{1,1} & Y_{1,2} & Y_{1,3} \\
  Y_{2,1} & Y_{2,2} & Y_{2,3} \\
  Y_{3,1} & Y_{3,2} & Y_{3,3} \\
  Y_{4,1} & Y_{4,2} & Y_{4,3} \\
  Y_{5,1} & Y_{5,2} & Y_{5,3} \\
  Y_{6,1} & Y_{6,2} & Y_{6,3} \\
  Y_{7,1} & Y_{7,2} & Y_{7,3} 
 \end{pmatrix} = 
  \begin{pmatrix}
  34 & 30 & 29 \\
  32 & 26 & 27 \\
  27 & 26 & 24 \\
  37 & 33 & 34 \\
  25 & 24 & 23 \\
  23 & 22 & 20 \\
  30 & 27 & 26 
 \end{pmatrix}
 (\#eq:math08)
\end{equation} 
  \
  \
In R we can define a matrix or a dataframe with rows and columns. We use a dataframe because it is the most common form for data in R and in science in general. Instead of Y, in the code below we call the data "Ydata" to avoid conflicts with the names of the vectors used above. First we make vectors of data for each crop and then we join them into a data frame with the `cbind` function, which stands for "column bind."

```{r}
wheat <- c(34, 32, 27, 37, 25, 23, 30)
corn <- c(30, 26, 26, 33, 24, 22, 27)
tomat <- c(29, 27, 24, 34, 23, 20, 26)

Ydata <- as.data.frame(cbind(wheat, corn, tomat))

Ydata

Ydata[5, 2] # Soil moisture for field 5 with corn

```

In general, for a table of values with k rows and r columns we write:

\begin{equation} 
\mathbf{Y}_{k,r} = 
 \begin{pmatrix}
  Y_{1,1} & Y_{1,2} & \cdots & Y_{1,r} \\
  Y_{2,1} & Y_{2,2} & \cdots & Y_{2,r} \\
  \vdots  & \vdots  & \ddots & \vdots  \\
  Y_{k,1} & Y_{k,2} & \cdots & Y_{k,r} 
 \end{pmatrix}
(\#eq:math09)
 \end{equation} 

If we want to average all values in the table we need to use a double summation to indicate that rathe sum is supposed to proceed over rows and columns. As an exercise to make sure you understand the subscripts, write down the matrix $\mathbf{Y}$ with all subscripts without looking at the book

\begin{equation} 
\begin{aligned}
&\sum_{i=1}^{i=7} \displaystyle\sum_{j=1}^{j=3} \frac{Y_{ij}} {7 \times 3} = 
\frac{1}{7 \times 3} \ \sum_{i=1}^{i=7}\sum_{j=1}^{j=3}Y_{ij} \\[20pt] 
&= \frac{1}{7 \times 3} \left( 
\sum_{j=1}^{j=3}Y_{1j} + 
\sum_{j=1}^{j=3}Y_{2j} + 
\sum_{j=1}^{j=3}Y_{3j} + 
\sum_{j=1}^{j=3}Y_{4j} + 
\sum_{j=1}^{j=3}Y_{5j} + 
\sum_{j=1}^{j=3}Y_{6j} + 
\sum_{j=1}^{j=3}Y_{7j} \right) \\[18pt]
&= \frac{1}{7 \times 3} \ (
Y_{11} + Y_{12} + Y_{13} + Y_{21} + Y_{22} + Y_{23} + Y_{31} + Y_{32} + Y_{33} \\
& \quad \qquad \quad + Y_{41} + Y_{42} + Y_{43} + Y_{51} + Y_{52} + Y_{53} + Y_{61} + Y_{62} + Y_{63} + Y_{71} + Y_{72} + Y_{73}) \\[20pt] 
& = \frac{1}{7 \times 3} \ (34 + 30 + 29 + 32 + 26 + 27 + 27 + 26 + 24 + 37 + 33 + 34 \\
&+ 25 + 24 + 23 + 23 + 22 + 20 + 30 + 27 + 26) = \frac{579}{21} = 27.57
\end{aligned}
(\#eq:math10)
\end{equation} 

Using R we can calculate the sums and the average very easily. Note that the functions `nrow` and `ncol` extract the number of rows and columns of a data frame or  matrix. The function `mean` give the average of the table.

```{r}

sum(Ydata) # Works only when all columns are numeric.

nrow(Ydata) # Ydata has 7 rows

ncol(Ydata) # and 3 columns.

sum(Ydata) / (nrow(Ydata) * ncol(Ydata))

mean(as.matrix(Ydata)) # Works only when all columns are numeric.

```



If we just want the average for corn we specify just the column for corn (column 2) and sum over all rows for column 2. If we want the results for a field or a set of fields, we specify the corresponding row numbers. Let's calculate the average moisture for corn and then the average for fields 3, 4, 5 and 7.

\begin{equation} 
\begin{aligned}
&corn \ average = \frac{1}{7} \left( \sum_{i=1}^{i=7}Y_{i2} \right) \\[15pt] 
&= \frac{1}{7} (Y_{12} + Y_{22} + Y_{32} + Y_{42} + Y_{52} + Y_{62} + Y_{72}) \\[15pt]
&= \frac{1}{7} (30 + 26 + 26 + 33 + 24 + 22 + 27) = 26.86
\end{aligned}
(\#eq:math11)
\end{equation} 

\begin{equation} 
\begin{aligned}
&fields \ 3, \ 4, \ 5 \ \& \ 7 \ average = \frac{1}{4 \times 3} \left( \sum_{j=1}^{j=3}Y_{3j} + 
\sum_{j=1}^{j=3}Y_{4j} + 
\sum_{j=1}^{j=3}Y_{5j} + 
\sum_{j=1}^{j=3}Y_{7j} \right) \\[20pt]
&= \frac{1}{4 \times 3} (Y_{31} + Y_{32} + Y_{33} + Y_{41} + Y_{42} + Y_{43} + Y_{51} + Y_{52} + Y_{53} + Y_{71} + Y_{72} + Y_{73}) \\[20pt]
&= \frac{1}{4 \times 3} (27 + 26 + 24 + 37 + 33 + 34 + 25 + 24 + 23 + 30 + 27 + 26) \\[20pt]
&= \frac{336}{12} = 28.0
\end{aligned}
(\#eq:math12)
\end{equation} 

We obtain those averges in R with the following code. Note that when we leave the place for row (or column) number empty, it is interpreted as all rows (or columns).

```{r}

mean(Ydata[, "corn"]) # Average for corn across fields

sum(Ydata[, 2])

length(Ydata[, 2])

sum(Ydata[, 2]) / length(Ydata[, 2])
```


## Models {#math.modl}

In statistics we use models all the time, and it is necessary to make those models explicit. Explicit models make it easier to understand and critically evaluate the use of statistics. Specifically, we can determine what parts of the model may be inadequate to solve the problem at hand, and we can modify the model to improve it.

### The simplest model{#math.smplMod}

Say that we are interested in studying the milk production per dairy cow in $kg \ day^{-1}$ for all dairy cows in the US today. For example, we want to estimate what proportion of cows produce less than $24 \ kg \ day^{-1}$ to gauge the number of cows that could be targets of a program to increase productivity. One way to do this is to create a *model* for the statistical distribution of milk production, take a sample to estimate the parameters of the model and then use the model with estimated parameters to make the estimation of the proportion of cows for which production is less than $24 \ kg \ day^{-1}$ or any other quantity.

A first attempt to estimate the needed proportion is to *model* milk production per cow as a normall distributed random variable with unknown mean and variance. Using the letter $Y$ to represent the milk production of a cow we write $Y \sim N(\mu, \sigma^2)$, which is read "Y is a random variable with normal distribution, with mean $\mu$ and variance $\sigma^2$." Sometimes we write $\sigma$, the standard deviation, instead of $\sigma^2$. Obviously, the standard deviation is the square root of the variance.

The model is not correct, and it could not be correct, for a number of reasons. First, normal distributions can take any values between $-\infty$ and $+\infty$, whereas milk production is zero or positive, but it cannot be negative. Moreover, if we are considering the population to be all the dairy cows in the US, althogh there are many dairy cows in the US (USDA estimated 9.3 million cows and heifers in 2014), the number is finite, whereas the normal dsitribution is for infinite populations. Yet, these flaws of our model are not important.

---

> Models are not supposed to be perfect representations of reality, they are supposed to be **useful** representations of reality.

---
Assuming that the variance of milk production is small relative to the mean, the fact that production has to be positive is not a problem, because a tiny and irrelevant piece of the distribution is expected to be below zero. The fact the the numebr of cows is finite is not a problem because we can either think of the total population as a very, very large sample of a truly infinite theoretical cow population or simply use the normal as an approximation to the truly discrete and finite real population.

The simple model that we are using can also be expressed as follows:

\begin{equation} 
\begin{aligned}
Y_i = \mu + \epsilon_i \\[10pt]
\epsilon_i \sim N(0, \sigma^2)
\end{aligned}
(\#eq:math13)
\end{equation} 

where $Y_i$ is the milk produced by cow number$i$, $\mu$ is the population mean and $\epsilon$ is a random variable with a normal distribution with mean 0 and variance $\sigma^2$. This is exactly the same model as before, but now we have isolated the deviations of each cow from the mean for the whole population which we call "errors" not because there is anthing wrong, but because we choose not to be interested in why cows differ in milk production per day. In this model, milk production is partitioned into an overall mean and a random "error."

The equation $\epsilon_i \sim N(0, \sigma^2)$ is actually a simplified version of $\epsilon_i \sim iid \quad N(0, \sigma^2) \quad \forall i$, which means that the errors for all observations have independent and identical normal distributions with mean 0 and variance $\sigma^2$. Why is it necessary to state this?! Isn't $\epsilon$ just one random variable? Actually, it does not have to be, so we need to specify how we are modeling the errors. In reality, it is possible for the error for each observation to come from a different distribution, although a model with such complexity would probably not be useful. Errors can also come from distributions that are not independent. The potential differences in error distributions and their correlations are topics for a more advanced course. At this point, you should just keep in mind that in real-world applications of statistics one frequently finds errors that are not normal, have unequal variances, and/or are correlated. The more advanced models necessary to deal with those situations include parts and parameters to deal with lack of normality, heterogeneity of variance and lack of independence.

In order to use the simple model to estimate the proportion of cows that produce less than $24 \ kg \ day^{-1}$ we can get a random sample of r cows and, based on that sample, estimate the mean as

\begin{equation} 
\hat{\mu} = \frac{1}{r} \sum_{i=1}^{i=r} Y_i 
(\#eq:math14)
\end{equation} 

and the variance as

\begin{equation} 
\hat{\sigma^2} =\frac{1}{r-1} \sum_{i=1}^{i=r} (Y_i-\hat{\mu})^2
(\#eq:math15)
\end{equation} 

where $e = \hat{\epsilon} = (Y_i-\hat{\mu})$ are the deviations of each cow from the estimated overall mean. These equations are presented with more detail in a later chapter (insert cross reference to chapter 06). Finally, the proportion of cows whose daily milk production is less than $24 \ kg \ day^{-1}$ is estimated as the area under the normal distribution curve between $-\infty$ and  $24 \ kg \ day^{-1}$. Using the capital letter$P$ to indicate "probability" we can write:

\begin{equation} 
\begin{aligned}
&\hat{P}(Y \le 24 \ kg \ day^{-1}) = area \ under \ curve = \int_{-\infty}^{24} f(Y) \ \mathrm{d}Y \\[20pt]
&where \ f(Y) = \frac{1}{{\hat{\sigma} \sqrt{2\pi}}} \  \mathrm{exp} \left( {  - \left( {x - \hat{\mu} } \right) ^ 2 / {2\hat{\sigma}^2}} \right)
\end{aligned}
(\#eq:math16)
\end{equation} 

Suppose that the estimated mean and variance were $28.3 \ kg \ day^{-1}$ and $25 \ kg^2 \ day^{-2}$. USDA reported an average production of $28.3 \ kg \ day^{-1}$ of milk per milking cow in 2016 (https://www.nass.usda.gov/Publications/Ag_Statistics/2017/Chapter08.pdf) . The variance was not reported, so we use a fictitious number. The area ander the curve would be calculated in R as follows (note how the code is written in several lines and indented for better readability):

```{r}

pnorm(           # function that calculates areas unde the normal
   q = 24,       # quantile desired, max. milk production in set
   mean = 28.3,    # mean of the normal distribution
   sd = 5        # standard distribution of the normal distribution
)

```


```{r message=FALSE, warning=FALSE, paged.print=FALSE, echo=FALSE, fig.cap="Simplest model for daily milk production per cow. The blue line is the probability density function (pdf) for a normal distribution with mean 28.3 and variance 25. According to this model, the area under the curve between any two values of Y (horizontal axis) represents the proportion of cows that have production between those values. The light blue area is the estimated proportion of cows that produce less than 24 kg per day. This is an estimated proportion because the actual mean and variance of the cow population are not known and were estimated based on a sample."}

library(plotrix)

x = seq(5, 50, length = 400)

y = dnorm(x, mean = 28.3, sd = 5)

plot(x, y, type = "l",
     lwd = 2, col = "blue", 
     xlab = "Y, milk production per cow in kg per day", 
     ylab = "f(Y), Normal probability density function")

x = seq(0, 24, length = 200)

y = dnorm(x, mean = 28.3, sd = 5)

polygon(c(0, x, 24), c(0, y, 0), col = "lightblue")

cow.prop <- as.character(
   round(
      pnorm(q = 24, mean = 28.3, sd = 5), 
      2)
)

text(x = 20.5, 
     y = 0.01, 
     labels = cow.prop)

temp <- textbox(x = c(4, 15), 
        y = 0.05, 
        cex = 0.9, 
        textlist = 
           c("Estimated proportion of cows ", 
             "that produce less than 24 kg per day"), 
        box = FALSE)

arrows(x0 = 13.5, y0 = 0.030, x1 = 20, y1 = 0.02, 
       length = 0.15, lwd = 2)

```

We used a very simple model for milk production with just two parameters, mean and variance. Mean and variance are called the "fixed" or non-random parts, and the error is the "random" component. When we use statistics and create models we need to choose what will be represented with fixed parameters and what parts will be represented with random variables or components. Except for the case where we consider subsampling, this course will only deal with models that have a single random component and we use the greek letter $\epsilon$ for it.

$$ data = Systematic \ Structure + Random \ Variation \\[10pt]
= Fixed \ Component + Random \ Component \\[10pt]
= Fixed \ Component + Structured \ Random + White \ Noise$$

Models that partition the random component into structured and unstructured (white noise) random parts are beyond the scope of this book.

### A slightly more complex model {#math.bttrMod}

The model used above and stated in equation \@ref(eq:math13) can be improved in many ways. For example, we may guess that a lot the variance in productivity can be between states, due to different levels of investment and development of the industry in different states. By adding a part to account for state in the fixed part of the model we can have much better predictions of the proportion of cows below $15 \ kg \ day^{-1}$ for each state. The model would look like this:

\begin{equation}
\begin{aligned}
Y_{ij} &= \mu_{i.} + \epsilon_{ij} \\[10pt]
&=  \mu_{..} + \tau_{i.} + \epsilon_{ij} \\[10pt]
\epsilon &\sim N(0, \sigma^2)
\end{aligned}
(\#eq:math17)
\end{equation}

where $\mu_{i.}$ is the mean for state $i$ and $\tau_{i.}$ is called the "effect" of state $i$. In general, when we have observations that are grouped lie cows in states, we can view the model as allowing a separate mean for each group or as each group having an effect on the mean. Both views are equivalent and their relationship is given by the fact that the efect is defined as the difference between each group mean and the overall mean: $\tau_{i.} = \mu_{i.} - \mu_{..}$. The "dots" in the subscript are used as place-holders for the subscript and to indicate that the average (or sum) has been done over all values of that subscript.


## Deviations, Errors and Residuals {#math.devs}

The difference between an observation and the mean is called a *deviation*, *residual* or *error*. The specific name depends on the context, but in general, we will use *deviation* for the total difference between observation and overall average, *residual* for the difference between an observation and the value estimated by a model, and *error* for the random component of a model.

\begin{equation} 
\begin{aligned}
&error = \epsilon &\textrm{a random variable}\\[15pt]
&total \ deviation = Y_{ij} - \mu{..} &\textrm{difference between observation and mean} \\[15pt]
&residual = e = \hat{\epsilon} = Y_{ij} - \hat{Y_{ij}} &\textrm{estimated error based on sample}
\end{aligned}
(\#eq:math18)
\end{equation}

The symbol $\hat{Y}_{ij}$ is read "Y hat sub i j" and it represents the value that would be expected for that observation if the experiment were repeated many, many times. Intuitively, it is the best guess that you have for the value that would be observed if a new measurement were done for $Y_{ij}$, based on data and model. Keep in mind that the subscripts depend on the organization of the data. For the simple model we only need one subscript because there are no goups.

Unfortunatley, the terms *error*, *deviation* and *residual* are frequently used interchangeably, but the good news is that the meaning can be easily derived from the context. **Errors** $\epsilon$ are usually unobservable and unknown, unless we create them in a computer simulation (see [Simulation](#math.simu) section). The main reason for this is that all measurements include some sort of random component that we cannot control, and that we usually do not know all the values in the population of interest.

Usually, population parameters are unknown and have to be estimated using samples, which is a main focus in statistics. With a model and a sample we can estimate parameter values, such as $\hat{\mu}$ and then by the difference we can estimate the errors. Estimated errors are called **residuals** in part because they are the parts of the observations that remain after all other parts accounted for by the model are subtracted. The total **deviation** is the difference between the value observed $Y_{ij}$ and the overall mean $\mu_{..}$, typically estimated with the overall average $\bar{Y}_{..}$.

In the two models above (equations \@ref(eq:math13) and \@ref(eq:math17) the equations to calculate the residuals are different, because observations are modeled differently. For the simple model, the best guess or estimate that we have for the production of a randomly selected cow (observation) is the overall average:

\begin{equation}
\hat{Y}_i = \hat{\mu} = \bar{Y}_. \\[10pt]
e = \hat{\epsilon} = Y_i - \hat{Y}_i  = Y_i - \hat{\mu} = Y_i - \bar{Y}_. \\[10pt]
= Observation - Fixed Component
(\#eq:math19)
\end{equation}

In this case of the simplest model, the error is equal to the total deviation, because the model does not have any other fixed component beyond the overall mean.

For the better model in equation \@ref(eq:math17), the fixed part of the model includes both an overall mean and a state effect $\tau_{i.}$ where $i$ is the subscript that specifies what state is being considered. The estimation for any given observation includes both components. Thus, the residual is the observed value $Y_{ij}$ minus the estimated overall mean $\bar{Y}_{..}$ minus the estimated state effect $\hat{\tau}_{i.}$.

\begin{equation}
\hat{Y}_{ij} = \hat{\mu}_{i.} = \bar{Y}_{i.} = \hat{\mu} + \hat{\tau}_{i.} = \bar{Y}_{..} + \hat{\tau}_{i.}\\[10pt]
e = \hat{\epsilon} = Y_{ij} - \hat{Y}_{ij}  = Y_{ij} - \bar{Y}_{i.} = Y_{ij} - \bar{Y}_{..} - \hat{\tau}_{i.}. \\[10pt]
(\#eq:math20)
\end{equation}

Keep in mind that the effect of state will be a negative number for those states that have mean milk production that is lower than the average for the whole country. We can use the values reported by USDA (2017) to determine the state effect for all states (\@ref(tab:math.tab01))

```{r math.tab01, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
#------dairy data-----
milk <- read.table(header = TRUE, text = "
State ncows1000 lb.cow.yr
Alabama 7.0 13143
Alaska 0.3 11667
Arizona 196.0 24429
Arkansas 6.0 13167
California 1762.0 22968
Colorado 151.0 25980
Connecticut 19.0 21474
Delaware 5.0 19100
Florida 123.0 20350
Georgia 84.0 21786
Hawaii 2.4 14542
Idaho 595.0 24647
Illinois 94.0 20245
Indiana 184.0 22560
Iowa 213.0 23634
Kansas 146.0 22801
Kentucky 58.0 18069
Louisiana 12.0 14083
Maine 30.0 21000
Maryland 48.0 19917
Massachusetts 12.0 17917
Michigan 419.0 25957
Minnesota 461.0 20967
Mississippi 10.0 14400
Missouri 88.0 15602
Montana 14.0 21071
Nebraska 60.0 23317
Nevada 30.0 22000
NewHampshire 14.0 20286
NewJersey 7.0 17429
NewMexico 315.0 24479
NewYork 620.0 23815
NorthCarolina 46.0 20978
NorthDakota 16.0 21563
Ohio 265.0 20875
Oklahoma 37.0 18703
Oregon 125.0 20744
Pennsylvania 529.0 20454
RhodeIsland 0.8 17500
SouthCarolina 15.0 16667
SouthDakota 115.0 22139
Tennessee 42.0 16571
Texas 475.0 22680
Utah 92.0 22772
Vermont 130.0 20954
Virginia 90.0 19144
Washington 276.0 24094
WestVirginia 9.0 14889
Wisconsin 1279.0 23552
Wyoming 6.0 23300
"
)

library(measurements)

milk$kg.d <- conv_unit(milk$lb.cow.yr, "lbs", "kg") / 365
milk.a <- milk[1:25, c(1,4)]
milk.b <- milk[26:50, c(1,4)]
knitr::kable(
   list(
      milk.a, 
      milk.b
   ),
   booktabs = TRUE, 
   row.names = FALSE, 
   caption = 'Milk production per lactating dairy cow in the US, by state in 2016. Based on USDA reports.'
)
```

### Simulation: Population is Known {#math.simu}


### Geometry of sums of squares (Maybe delete or mark as optional) {#ssGeom.math}

Remember the Pythagorean theorem? In a right triangle the square of the hypothenuse equals the sum of the squares of the sides. This can be extended to a polyhedron with right angles everywhere. The square of a diagonal in 3D is the sum of the three sides of the polyhedron. This square is also the sum of the square of the bottom hypothenuse and the vertical side squared. ** Add figure with labels** 
Imagine that we have a sample with 3 observations. Make a box where the lenght of each side is one of the observations and then consider the 3D diagonal. The sum of squares of the deviations is equal to the length of the diagonal.

The total sum of squares ...




## Optimization {#math.optim}

One way to "guess" or estimate the mean of a distribution that can be sampled directly is to take the average. The average minimizes the sum of the squared deviations of the obervations. Minimization of sums of squares is the most common method we will use to make estimates, but it is not the onlly method. Other method is to minimize the sum of the absolute deviations. The median of a set of observations is the value that minimizes the absolute deviations. "Absolute" means that all deviations are made positive.

Show an interactive graph where the values SS and SAD are shown as functions of the guessed mean. With and without outliers.

In many cases, the optimal value can be found analytically, which means that we can use an equation that yields the best estimate directly. This formula is obtained by taking the first derivative of the equation that calculates the SS as a function of the estimate, set it to zero and solve for the estimate. For more advanced statistical methods, there are no equations available, so numerical computations are used to approximated the optimal estimates.

Show pseudocode (set of ligical instructions in natural language) for an algorithm to find out what number I am thinking of just by asking if it is larger than a value that you choose for each question (or to numerically approximate a root of a polynomial).

Say what a polynomial is.

## Symbols and Terms{#math.symbls}

Observation
Expectation
Variance
Mean
Average
Sample Variance
Model
White noise
Random
$Y_i$
$Y_{ij}$
$Y_{ijh}$
$\epsilon$
$\bar{Y}_{i.}$
$\hat{Y}_{ij}$
$\hat{\mu}$
$\bar{Y}_{i.}$
$\hat{\tau}_{i.}$
$\tau_{i.}$
$\bar{Y}_{..}$
$\hat{Y}_i$
$\mu_{i.}$
$\hat{\sigma^2}$
$\sigma^2$
$\sigma$
$N(0, \sigma^2)$
$\sim$
$f(Y) = \frac{1}{{\hat{\sigma} \sqrt{2\pi}}} \  \mathrm{exp} \left( {  - \left( {x - \hat{\mu} } \right) ^ 2 / {2\hat{\sigma}^2}} \right)$
$\sum_{i=1}^{i=4} Y_i$
$\sum$
$$
$$
$$
$$
$$
$$
$$
$$
$$
$$
$$
$$
## Exercises and Solutions {#math.exe}

## Homework {#math.hwk}

## Laboratory Exercises {#math.lab}

### Plant Sciences

### Animal Sciences

