<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title></title>
  <meta name="description" content="">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  


<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Applied Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path=""><a href="#ch.chisq"><i class="fa fa-check"></i><b>1</b> Chi-square: Goodness of Fit and Test of Independence</a><ul>
<li class="chapter" data-level="1.1" data-path=""><a href="#learning-objectives-for-chapter"><i class="fa fa-check"></i><b>1.1</b> Learning Objectives for Chapter</a></li>
<li class="chapter" data-level="1.2" data-path=""><a href="#the-chi-square-chi2-distribution"><i class="fa fa-check"></i><b>1.2</b> The chi-square <span class="math inline">\(\chi^2\)</span> distribution</a></li>
<li class="chapter" data-level="1.3" data-path=""><a href="#goodness-of-fit-discrete-distributions"><i class="fa fa-check"></i><b>1.3</b> Goodness of Fit: Discrete distributions</a></li>
<li class="chapter" data-level="1.4" data-path=""><a href="#goodness-of-fit-continuous-distributions"><i class="fa fa-check"></i><b>1.4</b> Goodness of Fit: Continuous distributions</a></li>
<li class="chapter" data-level="1.5" data-path=""><a href="#the-chi2-test-of-independence-contingency-tables"><i class="fa fa-check"></i><b>1.5</b> The <span class="math inline">\(\chi^2\)</span> Test of Independence: Contingency Tables</a></li>
<li class="chapter" data-level="1.6" data-path=""><a href="#exercises-and-solutions"><i class="fa fa-check"></i><b>1.6</b> Exercises and Solutions</a></li>
<li class="chapter" data-level="1.7" data-path=""><a href="#homework-problems"><i class="fa fa-check"></i><b>1.7</b> Homework Problems</a></li>
<li class="chapter" data-level="1.8" data-path=""><a href="#LabCh14PLS"><i class="fa fa-check"></i><b>1.8</b> Laboratory Exercises</a><ul>
<li class="chapter" data-level="1.8.1" data-path=""><a href="#plant-sciences"><i class="fa fa-check"></i><b>1.8.1</b> Plant Sciences</a></li>
<li class="chapter" data-level="1.8.2" data-path=""><a href="#part-1-create-contingency-table"><i class="fa fa-check"></i><b>1.8.2</b> Part 1 Create contingency table</a></li>
<li class="chapter" data-level="1.8.3" data-path=""><a href="#part-2-expected-frequencies"><i class="fa fa-check"></i><b>1.8.3</b> Part 2: Expected Frequencies</a></li>
<li class="chapter" data-level="1.8.4" data-path=""><a href="#part-3-calculate-chi2"><i class="fa fa-check"></i><b>1.8.4</b> Part 3 Calculate <span class="math inline">\(\chi^{2}\)</span></a></li>
<li class="chapter" data-level="1.8.5" data-path=""><a href="#part4-results"><i class="fa fa-check"></i><b>1.8.5</b> Part4 Results</a></li>
<li class="chapter" data-level="1.8.6" data-path=""><a href="#animal-sciences"><i class="fa fa-check"></i><b>1.8.6</b> Animal Sciences</a></li>
<li class="chapter" data-level="1.8.7" data-path=""><a href="#part-1-create-contingency-table-1"><i class="fa fa-check"></i><b>1.8.7</b> Part 1 Create contingency table</a></li>
<li class="chapter" data-level="1.8.8" data-path=""><a href="#part-2-expected-frequencies-1"><i class="fa fa-check"></i><b>1.8.8</b> Part 2: Expected Frequencies</a></li>
<li class="chapter" data-level="1.8.9" data-path=""><a href="#part-3-calculate-chi2-1"><i class="fa fa-check"></i><b>1.8.9</b> Part 3 Calculate <span class="math inline">\(\chi^{2}\)</span></a></li>
<li class="chapter" data-level="1.8.10" data-path=""><a href="#part4-results-1"><i class="fa fa-check"></i><b>1.8.10</b> Part4 Results</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:title:end-->
<!--bookdown:title:start-->
<div id="ch.chisq" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Chi-square: Goodness of Fit and Test of Independence</h1>
<div id="learning-objectives-for-chapter" class="section level2">
<h2><span class="header-section-number">1.1</span> Learning Objectives for Chapter</h2>
<p>Jen’s: 1. Construct a contingency table and calculate its degrees of freedom. 2. State if a larger or smaller chi square value indicates stronger dependency between variables in a test of independence. 3. Describe the theory behind how we calculate the expected values in a test of independence.</p>
<ol style="list-style-type: decimal">
<li>Define independence between random variables.</li>
<li>Identify problems that can be addressed as goodness of fit or independence tests.</li>
<li>Define degrees of freedom for the <span class="math inline">\(\chi^2\)</span> distribution.</li>
<li>Test for independence of categorical random variables.</li>
<li>Test the goodness of fit of theoretical distributions to data.</li>
<li>Look up quantiles and probabilities for the <span class="math inline">\(\chi^2\)</span> distribution.</li>
</ol>
</div>
<div id="the-chi-square-chi2-distribution" class="section level2">
<h2><span class="header-section-number">1.2</span> The chi-square <span class="math inline">\(\chi^2\)</span> distribution</h2>
<p>The chi-square <span class="math inline">\(\chi^2\)</span> distribution is widely used in a variety of statistical tests. If describes the distribution of the sum of the squares of k independent standard normal random variables. Two of the most important applications of the <span class="math inline">\(\chi^2\)</span> distribution are the test for goodness of fit of an observed distribution to a theoretical one and the test of independence between two categorical random variables.</p>
<p>In both tests, we calculate a <span class="math inline">\(\chi^2\)</span> test statistic based the differences between observed and expected frequencies, given some theoretical model.</p>
<p>ADD: PLOT OF CHI SQUARE HERE</p>
</div>
<div id="goodness-of-fit-discrete-distributions" class="section level2">
<h2><span class="header-section-number">1.3</span> Goodness of Fit: Discrete distributions</h2>
<p>In goodness of fit tests for discrete distributions, we are dealing with a single random variable with discrete classes. Supposed we take a sample from a population with k different classes for the random variable. We have an expected theoretical probability distribution across the k classes and want to test the “goodness of fit” of the population to the theoretical distribution using our sample.<br />
Our data would consist of k observed frequencies (<span class="math inline">\(O_1:O_k\)</span>), which we would compare to k expected frequencies (<span class="math inline">\(E_1:E_k\)</span>). Then we can calculate <span class="math inline">\(\chi^2\)</span> as</p>
<span class="math display" id="eq:chi">\[\begin{equation}
\chi^2 = \sum_{i = 1}^k \frac{(O_i - E_i)^2}{E_i}
,\; df = k-1
\tag{1.1}
\end{equation}\]</span>
<p>If there are only 2 classes involved (i.e., k = 2, df = 1), then we use an adjusted <span class="math inline">\(\chi^2\)</span> formula:</p>
<span class="math display" id="eq:chiadj">\[\begin{equation}
\chi^2_{adj} = \sum_{i = 1}^2 \frac{(\mid{O_i - E_i}\mid - 1/2)^2}{E_i}
,\; df = 1
\tag{1.2}
\end{equation}\]</span>
<p>The smaller the differences between the observed frequencies and what we expected based on our theoretical model, the smaller the <span class="math inline">\(\chi^2\)</span> value. The larger ther <span class="math inline">\(\chi^2\)</span> values, the less likely our results will support that the population follows our theoretical distribution. This deviates from previous tests, where our general desire was the reject the null hypothesis, because it meant that there was a significant effect of some variable of interest on another. Here, our null hypothesis is that the variable in our population of interest follows our theoretical distribution, and to reject the null hypothesis would suggest that it does not.</p>
<p>An example of a discrete theoretical distribution for a single variable is based on Mendel’s experiments with the common pea. He studied seven traits in total, but we will focus on two: seed shape and seed color. Mendel produced an F1 generation from crossing true-breeding parental pea plants producing wrinkled seeds (the recessive trait) with true-breeding parental plants that produced round seeds (the dominant trait). All of the F1 produced round seeds. He then produced an F2 generation through self-fertilization of the F1 hybrids, and this time he observed a 3:1 phenotypic ratio of smooth to wrinkled. This ratio of 3:1 for the dominant to recessive phentoypic traits was true in all of the traits he studied. We can use his dataset on pea seed shape to test the goodness of fit to a 3:1 ratio.</p>
<p>These were the observed frequencies for each seed shape phenotype:</p>
<pre><code>## [1] 423 133</code></pre>
<p>We first sum the total number of pea observations to calculate the expected frequencies under a 3:1 ratio.<br />
<span class="math inline">\(423 + 133 = 556\)</span></p>
<p>Then we can figure out the expected values given a 3:1 ratio:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Er &lt;-<span class="st"> </span>(<span class="dv">556</span><span class="op">/</span><span class="dv">4</span>)<span class="op">*</span><span class="dv">3</span>

Ew &lt;-<span class="st"> </span>(<span class="dv">556</span><span class="op">/</span><span class="dv">4</span>)<span class="op">*</span><span class="dv">1</span>

(Expected &lt;-<span class="st"> </span><span class="kw">c</span>(Er, Ew))</code></pre></div>
<pre><code>## [1] 417 139</code></pre>
<p>Now, we can combine the expected frequenices with the observed frequencies in a table:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mTab &lt;-<span class="st"> </span><span class="kw">data.frame</span>(Observed, Expected)
<span class="kw">rownames</span>(mTab) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;round&quot;</span>, <span class="st">&quot;wrinkled&quot;</span>)
mTab</code></pre></div>
<pre><code>##          Observed Expected
## round         423      417
## wrinkled      133      139</code></pre>
<p>We can calculate a <span class="math inline">\(\chi^2\)</span> value for both seed shapes, but we will need to use the <span class="math inline">\(\chi^2_{adj}\)</span> formula because we only have <span class="math inline">\(k - 2\)</span> classes.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(chiAdj &lt;-<span class="st"> </span><span class="kw">sum</span>((<span class="kw">abs</span>(Observed <span class="op">-</span><span class="st"> </span>Expected) <span class="op">-</span><span class="st"> </span><span class="fl">0.5</span>)<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>Expected))</code></pre></div>
<pre><code>## [1] 0.2901679</code></pre>
<p>We now have a <span class="math inline">\(\chi^2_{adj}\)</span> test statistic that we can compare to a critical <span class="math inline">\(\chi^2\)</span> value with <span class="math inline">\(df = 1\)</span> at <span class="math inline">\(\alpha = 0.05\)</span>. In R, we can use the qchisq() function to get a critical <span class="math inline">\(\chi^2\)</span> value, and the pchisq() function to obtain a p value for our test statistic:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(criticalChi &lt;-<span class="st"> </span><span class="kw">qchisq</span>(<span class="dt">p =</span> <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.05</span>, <span class="dt">df =</span> <span class="dv">1</span>))</code></pre></div>
<pre><code>## [1] 3.841459</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(pval &lt;-<span class="st"> </span><span class="kw">pchisq</span>(chiAdj, <span class="dt">df =</span> <span class="dv">1</span>, <span class="dt">lower.tail =</span> F))</code></pre></div>
<pre><code>## [1] 0.590113</code></pre>
<p>As you can see, our <span class="math inline">\(\chi^2_{adj}\)</span> value of 0.29 is much smaller than the critical <span class="math inline">\(\chi^2\)</span> value of 3.84, and our p value is 0.59. There is a 59% probability of seeing our results or more extreme results if the null hypothesis was true. We therefore conclude that our observed phenotypic ratio matches the expected ratio of 3:1.</p>
<p>We can use the same data to test the assumption that the combination of two traits will have a phenotypic ratio of 9:3:3:1 under Mendel’s law of independent assortment. We will look at the combination of seed shape and color, with round/yellow(RY), round/green (RG), wrinkled/yellow (WY), and wrinkled/green (WG) as the possible phenotypes. For seed color, yellow is the dominant trait. We would expect to see the phenotypes to follow a 9:3:3:1 ratio in the order RY:RG:WY:WG.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mendel</code></pre></div>
<pre><code>##      shape  color both count
## 1    round yellow   RY   315
## 2    round  green   RG   108
## 3 wrinkled yellow   WY   101
## 4 wrinkled  green   WG    32</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(Observed2 &lt;-<span class="st"> </span>mendel[,<span class="kw">c</span>(<span class="dv">3</span><span class="op">:</span><span class="dv">4</span>)])</code></pre></div>
<pre><code>##   both count
## 1   RY   315
## 2   RG   108
## 3   WY   101
## 4   WG    32</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Just as before, the total number of plants is 556.  </span>
ExpRY &lt;-<span class="st"> </span><span class="dv">9</span><span class="op">*</span>(<span class="dv">556</span><span class="op">/</span><span class="dv">16</span>)
ExpRG &lt;-<span class="st"> </span><span class="dv">3</span><span class="op">*</span>(<span class="dv">556</span><span class="op">/</span><span class="dv">16</span>)
ExpWY &lt;-<span class="st"> </span><span class="dv">3</span><span class="op">*</span>(<span class="dv">556</span><span class="op">/</span><span class="dv">16</span>)
ExpWG &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">*</span>(<span class="dv">556</span><span class="op">/</span><span class="dv">16</span>)

(Expected2 &lt;-<span class="st"> </span><span class="kw">c</span>(ExpRY, ExpRG, ExpWY, ExpWG))</code></pre></div>
<pre><code>## [1] 312.75 104.25 104.25  34.75</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mTab2 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(Observed2, Expected2)

mTab2</code></pre></div>
<pre><code>##   both count Expected2
## 1   RY   315    312.75
## 2   RG   108    104.25
## 3   WY   101    104.25
## 4   WG    32     34.75</code></pre>
<p>We can use the regular <span class="math inline">\(\chi^2\)</span> formula to obtain our test statistic because we have more than 2 classes:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(chi2 &lt;-<span class="st"> </span><span class="kw">sum</span>((Observed2<span class="op">$</span>count <span class="op">-</span><span class="st"> </span>Expected2)<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>Expected2))</code></pre></div>
<pre><code>## [1] 0.470024</code></pre>
<p>And use R to find a critical <span class="math inline">\(\chi^2\)</span> value and p value again:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">k &lt;-<span class="st"> </span><span class="dv">4</span> <span class="co"># We have 4 classes</span>

(criticalChi2 &lt;-<span class="st"> </span><span class="kw">qchisq</span>(<span class="dt">p =</span> <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.05</span>, <span class="dt">df =</span> k<span class="op">-</span><span class="dv">1</span>))</code></pre></div>
<pre><code>## [1] 7.814728</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(pval2 &lt;-<span class="st"> </span><span class="kw">pchisq</span>(chi2, <span class="dt">df =</span> k<span class="op">-</span><span class="dv">1</span>, <span class="dt">lower.tail =</span> F))</code></pre></div>
<pre><code>## [1] 0.9254259</code></pre>
<p>We once again fail to reject the null hypothesis because our p value is much greater than 0.05.</p>
<p>We can also use the chisq.test() function in R to perform these tests very easily. We will demonstrate how to do this using the test for two traits. The function requires two arguments for a goodness of fit test: \ x = vector of observed frequencies \ p = vector of expected probabilities \</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span>Observed2<span class="op">$</span>count
p &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">9</span><span class="op">/</span><span class="dv">16</span>, <span class="dv">3</span><span class="op">/</span><span class="dv">16</span>, <span class="dv">3</span><span class="op">/</span><span class="dv">16</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">16</span>)

<span class="kw">chisq.test</span>(<span class="dt">x =</span> x, <span class="dt">p =</span> p)</code></pre></div>
<pre><code>## 
##  Chi-squared test for given probabilities
## 
## data:  x
## X-squared = 0.47002, df = 3, p-value = 0.9254</code></pre>
<p>You can see that all results from the chisq.test() function match our calculations exactly.</p>
</div>
<div id="goodness-of-fit-continuous-distributions" class="section level2">
<h2><span class="header-section-number">1.4</span> Goodness of Fit: Continuous distributions</h2>
<p>We often wish to know if our data follows a particular continuous probability distribution. One common application of a <span class="math inline">\(\chi^2\)</span> goodness of fit test for a continuous distribution is to test if continuous data follows a normal distribution.</p>
<p>To perform this test, we bin the continuous data into discrete classes of equal intervals so that we can calculate a <span class="math inline">\(\chi^2\)</span> value for each discrete interval and sum them to obtain an overall <span class="math inline">\(\chi^2\)</span>test statistic. We will use 144 adult cat heart weights from a free dataset that comes with the MASS package in R (cats) to test that the cat heart weights are normally distributed.</p>
<p>First, we order the observations from smallest to largest, then set up vectors that record the midpoints and endpoints of 9 discrete bins of the data range:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(MASS)
cwt &lt;-<span class="st"> </span>cats

<span class="co">#sorting the heart weights into a vector</span>
weights &lt;-<span class="st"> </span><span class="kw">sort</span>(cwt<span class="op">$</span>Hwt)</code></pre></div>
<p>Now, we can do a quick check to see if the data appears normally distributed before even doing our goodness of fit test:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(weights)</code></pre></div>
<p><img src="14.0_ChiSquare_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>The data looks right-skewed, so we might consider log-transforming the weights to make them more normally distributed:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(<span class="kw">log</span>(weights))</code></pre></div>
<p><img src="14.0_ChiSquare_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>That looks much better. We will use the log-transformed heart weights instead to test for normality.</p>
<p>First, we will set up a vector containing the endpoints of 9 discrete intervals of equal length within the range of observed log(weight) values:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">classes &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">9</span> <span class="co">#number of intervals</span>

<span class="co">#log transform</span>
logwt &lt;-<span class="st"> </span><span class="kw">log</span>(weights)

<span class="co">#Get the total range of values:</span>
range &lt;-<span class="st"> </span><span class="kw">max</span>(logwt) <span class="op">-</span><span class="st"> </span><span class="kw">min</span>(logwt) 

<span class="co">#Length of each bin interval when k = 9:</span>
binInt &lt;-<span class="st"> </span>range<span class="op">/</span><span class="dv">9</span>

<span class="co">#The endpoints of the bin intervals:</span>
endpoints &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="kw">min</span>(logwt), <span class="kw">max</span>(logwt), binInt)</code></pre></div>
<p>The next part is a little trickier. We need to get a frequency of observed weights in each bin interval. We will show you how to do this using a for loop in R.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#set up a vector of NAs that will hold the observed frequencies</span>
Ofreq &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="dv">9</span>)
<span class="co">#We use a logical query for each interval, where we ask which logwts are less than or equal to endpoint i, starting at i = 2 since the first endpoint is the minimum logwt., and greater than the previous endpoint.</span>
<span class="co">#Then we sum each result to get the frequency of observations in each interval i.</span>

<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span><span class="dv">10</span>){
   Ofreq[i<span class="op">-</span><span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">sum</span>(logwt <span class="op">&gt;</span><span class="st"> </span>(endpoints[i<span class="op">-</span><span class="dv">1</span>]) <span class="op">&amp;</span><span class="st"> </span>
<span class="st">                      </span>logwt <span class="op">&lt;=</span><span class="st"> </span>endpoints[i])
}

<span class="co">#we add 1 to Ofreq[1] since the minimum logwt value was not included in the first interval frequency using the code above. </span>
Ofreq[<span class="dv">1</span>] &lt;-<span class="st"> </span>Ofreq[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span><span class="dv">1</span> 

Ofreq</code></pre></div>
<pre><code>## [1]  5 16 25 37 25 22 11  2  1</code></pre>
<p>Now that we have all of our observed frequencies, we need to work on getting expected frequencies under the null hypothesis that our data are normally distributed. We first find the z score for each interval using the endpoint of the interval, the standard deviation of the weights, and the total mean of the weights:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">meanWt &lt;-<span class="st"> </span><span class="kw">mean</span>(logwt)
sdWt &lt;-<span class="st"> </span><span class="kw">sd</span>(logwt)
(zscores &lt;-<span class="st"> </span>(endpoints[<span class="op">-</span><span class="dv">1</span>] <span class="op">-</span><span class="st"> </span>meanWt) <span class="op">/</span><span class="st"> </span>sdWt)</code></pre></div>
<pre><code>## [1] -1.6526552 -1.0627105 -0.4727659  0.1171788  0.7071235  1.2970681
## [7]  1.8870128  2.4769574  3.0669021</code></pre>
<p>We can now use the z scores to find the probability within each interval from a standard normal probability distribution. We can do this by finding the left-tailed cumulative probability at each endpoint and substracting the left-tailed cumulative probability at the previous endpoint. For example, if we have the probability at a z score of -1:</p>
<pre><code>## [1] 0.1586553</code></pre>
<p><img src="14.0_ChiSquare_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>And we know the left-tailed probability at z = -2:</p>
<pre><code>## [1] 0.02275013</code></pre>
<p><img src="14.0_ChiSquare_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>Then the probability between <span class="math inline">\(z = -2\)</span> and <span class="math inline">\(z = -1\)</span> is <span class="math inline">\(p(z \leq{-1}) - p(z \leq{-2})\)</span>:</p>
<pre><code>## [1] 0.1359051</code></pre>
<p><img src="14.0_ChiSquare_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>To calculate this in R, we can use the pnorm() function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pnorm</span>(<span class="op">-</span><span class="dv">1</span>) <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="op">-</span><span class="dv">2</span>)</code></pre></div>
<pre><code>## [1] 0.1359051</code></pre>
<p>We will do this for each interval endpoint in our logwt dataset using a for loop:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">probs &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="dv">9</span>)
probs[<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(zscores[<span class="dv">1</span>])

<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span><span class="dv">9</span>){
   probs[i] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(zscores[i]) <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(zscores[i<span class="op">-</span><span class="dv">1</span>])
}</code></pre></div>
<p>Now that we have the expected probabilities for each interval if our data were normally distributed, we can calculate expected frequencies by multiplying the expected probabilities by the total number of logwts in our dataset:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(Efreq &lt;-<span class="st"> </span>probs <span class="op">*</span><span class="st"> </span><span class="kw">sum</span>(Ofreq))</code></pre></div>
<pre><code>## [1]  7.0848766 13.6448776 25.0896229 32.8969006 30.7604596 20.5115046
## [7]  9.7523384  3.3053643  0.7983269</code></pre>
<p>For each interval, we can calculate the squared deviation of the observed frequency from the expected frequency divided by the expected frequency, and then sum these values up to obtain our <span class="math inline">\(\chi^2\)</span> statistic:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(chiSq &lt;-<span class="st"> </span>(<span class="kw">sum</span>((Ofreq <span class="op">-</span><span class="st"> </span>Efreq)<span class="op">^</span><span class="dv">2</span><span class="op">/</span>Efreq)))</code></pre></div>
<pre><code>## [1] 3.444954</code></pre>
<p>And as per usual, we can compare this <span class="math inline">\(\chi^2\)</span> statistic to a critical <span class="math inline">\(\chi^2\)</span> and obtain a p value.</p>
<p>The number of degrees of freedom is in general the total number of dimensions in which the results can vary. For the test of goodness of fit, the degrees of freedom are the total number of observed values used in the calculation of <span class="math inline">\(\chi^2\)</span> minus the number of calculated values or parameters used to estimate the expected values. In this example, we have 9 observed frequencies, and in order to calculate the expected frequencies, we used the total number of observations (144), the estimated mean (2.34) and the estimated standard deviation (0.22). Therefore, <span class="math inline">\(df = 9 - 3\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">k &lt;-<span class="st"> </span><span class="dv">9</span>

<span class="co">#Critical chi-squared value at alpha = 0.05</span>
<span class="kw">qchisq</span>(<span class="dt">p =</span> <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.05</span>, <span class="dt">df =</span> k<span class="op">-</span><span class="dv">3</span>)</code></pre></div>
<pre><code>## [1] 12.59159</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#p value at our test statistic</span>
<span class="kw">pchisq</span>(chiSq, k<span class="op">-</span><span class="dv">3</span>, <span class="dt">lower.tail =</span> F)</code></pre></div>
<pre><code>## [1] 0.7512784</code></pre>
<p>We can see that our <span class="math inline">\(\chi^2\)</span> test statistic is much smaller than the critical value and that p &gt; 0.05, so we fail to reject the null hypothesis that the log of the cat heart weight data is normally distributed.</p>
</div>
<div id="the-chi2-test-of-independence-contingency-tables" class="section level2">
<h2><span class="header-section-number">1.5</span> The <span class="math inline">\(\chi^2\)</span> Test of Independence: Contingency Tables</h2>
<p>The test of independence is related to the goodness of fit test. Just as in goodness of fit tests, we are concerned with observed frequencies versus expected frequencies under a theoretical model. The theoretical model in the case of the test of independence is specifically that two categorical variables are independent. The categorical variables each have a number of classes. When we classify our observations according to the two variables in a two way table with j rows and k columns, then we create a <strong>contingency table</strong>. For such a contingency table, <span class="math inline">\(df = (j-1)(k-1)\)</span>.</p>
<p>We show an example of a contingency table in Table <a href="#tab:cont">1.1</a>.</p>
<table>
<caption><span id="tab:cont">Table 1.1: </span>Observed frequencies of common versus rare plant species in South Australia and Victoria, Australia according to habitat type (dry only, wet only, and wet or dry).</caption>
<thead>
<tr class="header">
<th align="left">Species type</th>
<th align="right">Dry</th>
<th align="right">Wet</th>
<th align="right">Wet or Dry</th>
<th align="right">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">common</td>
<td align="right">60</td>
<td align="right">249</td>
<td align="right">117</td>
<td align="right">426</td>
</tr>
<tr class="even">
<td align="left">rare</td>
<td align="right">25</td>
<td align="right">199</td>
<td align="right">44</td>
<td align="right">268</td>
</tr>
<tr class="odd">
<td align="left">Total</td>
<td align="right">85</td>
<td align="right">448</td>
<td align="right">161</td>
<td align="right">694</td>
</tr>
</tbody>
</table>
<p>Does habitat (wet or dry) influence the prevalence of common or rare plant sepcies in South Australia and Victoria?</p>
<p>The null hypothesis of our test is that the habitat type and species type are independent of one another. We have observed frequencies in the table above, but how do we calculate expected frequencies? We have to understand that if the two variables are independent, then the joint probability in each cell of our contingency table will be the product of the corresponding row and colum marginal probabilities. In other words, the joint probability of a plant species being both common and found in a dry only habitat would equal the probability of it being found in a dry only habitat multiplied by the probability of it being common, <em>if</em> the habitat type and species type are indendent of one another.</p>
<p>We first build a table that contains the estimated joint probabilities for each cell under the null hypothesis of independence.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#create a table from the original data table, with appropriate dimensions just to hold joint probabilities:</span>
plantP &lt;-<span class="st"> </span>planttab[<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>,<span class="dv">2</span><span class="op">:</span><span class="dv">4</span>] 
<span class="co">#total sample size:</span>
Grand &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(planttab[<span class="dv">3</span>,<span class="dv">5</span>])
<span class="co">#Create vectors of the marginal probabilities</span>
(HabP &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(planttab[<span class="dv">3</span>,<span class="dv">2</span><span class="op">:</span><span class="dv">4</span>])<span class="op">/</span>Grand)</code></pre></div>
<pre><code>## [1] 0.1224784 0.6455331 0.2319885</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(SpP &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(planttab[<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>,<span class="dv">5</span>])<span class="op">/</span>Grand)</code></pre></div>
<pre><code>## [1] 0.6138329 0.3861671</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#multiply the row and column marginal probabilities to get the joint probabilities in each cell:</span>
<span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>){
   <span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>){
      plantP[j,k] &lt;-<span class="st"> </span>SpP[j] <span class="op">*</span><span class="st"> </span>HabP[k]
   }
}

<span class="kw">rownames</span>(plantP) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;common&quot;</span>, <span class="st">&quot;rare&quot;</span>)
knitr<span class="op">::</span><span class="kw">kable</span>(<span class="dt">x =</span> <span class="kw">round</span>(plantP,<span class="dv">2</span>),
             <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;Dry&quot;</span>, <span class="st">&quot;Wet&quot;</span>, <span class="st">&quot;Wet or Dry&quot;</span>), 
             <span class="dt">caption =</span> <span class="st">&quot;Joint probabilities given the marginal probabilities in rows and columns&quot;</span>
)</code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-24">Table 1.2: </span>Joint probabilities given the marginal probabilities in rows and columns</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">Dry</th>
<th align="right">Wet</th>
<th align="right">Wet or Dry</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>common</td>
<td align="right">0.08</td>
<td align="right">0.40</td>
<td align="right">0.14</td>
</tr>
<tr class="even">
<td>rare</td>
<td align="right">0.05</td>
<td align="right">0.25</td>
<td align="right">0.09</td>
</tr>
</tbody>
</table>
<p>Now that we have theoretical probabilities, we can multiply them by the total sample size (n = 694) to obtain expected frequencies in each cell of our contingency table.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Exp &lt;-<span class="st"> </span>plantP <span class="op">*</span><span class="st"> </span>Grand
knitr<span class="op">::</span><span class="kw">kable</span>(<span class="dt">x =</span> Exp,
             <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;Dry&quot;</span>, <span class="st">&quot;Wet&quot;</span>, <span class="st">&quot;Wet or Dry&quot;</span>), 
             <span class="dt">caption =</span> <span class="st">&quot;Expected frequencies if the rareness of plant species was independent of habitat type&quot;</span>
)</code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-25">Table 1.3: </span>Expected frequencies if the rareness of plant species was independent of habitat type</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">Dry</th>
<th align="right">Wet</th>
<th align="right">Wet or Dry</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>common</td>
<td align="right">52.17579</td>
<td align="right">274.9971</td>
<td align="right">98.82709</td>
</tr>
<tr class="even">
<td>rare</td>
<td align="right">32.82421</td>
<td align="right">173.0029</td>
<td align="right">62.17291</td>
</tr>
</tbody>
</table>
<p>We know that we have <span class="math inline">\((2-1) \times (3-1) = 2\)</span> degrees of freedom, so there is no need to use the <span class="math inline">\(\chi^2_{adj}\)</span> formula. We can find the sum of each cell contribution to the test statistic using the normal <span class="math inline">\(\chi^2\)</span> formula, equation <a href="#eq:chi">(1.1)</a>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Matrices of the observed and expected frequencies:</span>
Obs &lt;-<span class="st"> </span><span class="kw">apply</span>(planttab[<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>, <span class="dv">2</span><span class="op">:</span><span class="dv">4</span>], <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="st">&quot;as.numeric&quot;</span>)
Exp</code></pre></div>
<pre><code>##               D        W       WD
## common 52.17579 274.9971 98.82709
## rare   32.82421 173.0029 62.17291</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(chiSq &lt;-<span class="st"> </span><span class="kw">sum</span>((Obs <span class="op">-</span><span class="st"> </span>Exp)<span class="op">^</span><span class="dv">2</span><span class="op">/</span>Exp))</code></pre></div>
<pre><code>## [1] 18.0562</code></pre>
<p>Our critical <span class="math inline">\(\chi^2\)</span> value and p value are:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(crit &lt;-<span class="st"> </span><span class="kw">qchisq</span>(<span class="dv">1</span><span class="op">-</span><span class="fl">0.05</span>, <span class="dt">df =</span> <span class="dv">2</span>))</code></pre></div>
<pre><code>## [1] 5.991465</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(pval &lt;-<span class="st"> </span><span class="kw">pchisq</span>(chiSq, <span class="dt">df =</span> <span class="dv">2</span>, <span class="dt">lower.tail =</span> F))</code></pre></div>
<pre><code>## [1] 0.0001199901</code></pre>
<p>We can also use the chisq.test() function in R to perform the same test:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">chisq.test</span>(Obs)</code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  Obs
## X-squared = 18.056, df = 2, p-value = 0.00012</code></pre>
<p>You can see we obtain identical results.</p>
<p>We see that our test statistic is much larger than our critical value (18.06 &gt; 5.99), and that our p value (<span class="math inline">\(p = 0.00012\)</span>) is much smaller than 0.05. We reject the null hypothesis and conclude that habitat type <em>does</em> have a relationship with the rareness of plant species in South Australia and Victoria.</p>
<p>If we take a closer look at the individual contributions to the <span class="math inline">\(\chi^2\)</span> statistic:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(Obs <span class="op">-</span><span class="st"> </span>Exp)<span class="op">^</span><span class="dv">2</span><span class="op">/</span>Exp</code></pre></div>
<pre><code>##               D        W       WD
## common 1.173307 2.457663 3.341742
## rare   1.865033 3.906583 5.311874</code></pre>
<p>we see that the frequency of rare plants in wet and wet or dry habitats in particular have larger deviations of observed from expected frequencies.</p>
<p>Lets look again at our original observed frequencies and compare with our expected frequencies.</p>
<p>Observed:</p>
<table>
<thead>
<tr class="header">
<th align="left">Species type</th>
<th align="right">Dry</th>
<th align="right">Wet</th>
<th align="right">Wet or Dry</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">common</td>
<td align="right">60</td>
<td align="right">249</td>
<td align="right">117</td>
</tr>
<tr class="even">
<td align="left">rare</td>
<td align="right">25</td>
<td align="right">199</td>
<td align="right">44</td>
</tr>
</tbody>
</table>
<p>Expected:</p>
<table>
<thead>
<tr class="header">
<th align="left">Species type</th>
<th align="right">Dry</th>
<th align="right">Wet</th>
<th align="right">Wet or Dry</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">common</td>
<td align="right">52</td>
<td align="right">275</td>
<td align="right">99</td>
</tr>
<tr class="even">
<td align="left">rare</td>
<td align="right">33</td>
<td align="right">173</td>
<td align="right">62</td>
</tr>
</tbody>
</table>
</div>
<div id="exercises-and-solutions" class="section level2">
<h2><span class="header-section-number">1.6</span> Exercises and Solutions</h2>
</div>
<div id="homework-problems" class="section level2">
<h2><span class="header-section-number">1.7</span> Homework Problems</h2>
</div>
<div id="LabCh14PLS" class="section level2">
<h2><span class="header-section-number">1.8</span> Laboratory Exercises</h2>
<pre><code>---
title: &quot;Lab14 Chi Square: Contingency Tables&quot;
author: &quot;YourFirstName YourLastName&quot;
date: &quot;enter date here&quot;
output: html_document
---</code></pre>
<div id="plant-sciences" class="section level3">
<h3><span class="header-section-number">1.8.1</span> Plant Sciences</h3>
<p>We can use the <span class="math inline">\(\chi^{2}\)</span> distribution to test for a relationship between two categorical variables. This type of test is called a <strong>test of independence</strong>. We specifically test the null hypothesis that there is statistical independence between the two categorical variables. We will be working on a dataset published by <span class="citation">@PierantozziPierluigi2012PaCI</span>. They were interested in the effect of olive plant cultivar type on the number of seeds produced per olive fruit. Olive fruit can contain 1, 2, or no seeds. The common case is 1 seed, though rarely they will contain two seeds, and some may contain no seeds at all due to embryo death. In 2007, they collected 1,072 olives from different cultivar plants in Central Italy, noting the number of seeds each fruit contained.</p>
<p>To perform this test of independence, we will (1) create a contingency table, (2) calculate the frequencies we would expect to observe if cultivar type and number of seeds are independent, (3) calculate a <span class="math inline">\(\chi^{2}\)</span> test statistic that contains information about the deviation of our observations from what is expected under <span class="math inline">\(H_{0}\)</span> , and finally (4) compare the <span class="math inline">\(\chi^{2}\)</span> test statistic against the critical <span class="math inline">\(\chi^{2}\)</span> value to decide if we reject or fail to reject <span class="math inline">\(H_{0}\)</span></p>
</div>
<div id="part-1-create-contingency-table" class="section level3">
<h3><span class="header-section-number">1.8.2</span> Part 1 Create contingency table</h3>
<p>The first step in performing a test of independence is to build a <strong>contingency table</strong> with j rows and k columns. One variable is classed into j factor levels in the rows, and the second variable is classed into k factor levels in the columns. The frequencies of each combination of attributes between the two variables fill the table and are used to calculate the marginal totals for each attribute.</p>
<p>1A) Read in the olive data set as a csv file 1B) Create a contingency table using the table() function.<br />
1C) Calculate the marginal totals of each attribute type of each of the two variables.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">olives &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;./Datasets/olives.csv&quot;</span>)

##use table() to calculate the frequencies of each cultivar/No.seeds combination in the data. 
(olivect &lt;-<span class="st"> </span><span class="kw">table</span>(olives))</code></pre></div>
<pre><code>##                  No.Seeds
## cultivar            0   1   2
##   Ascolana Tenera  29  91  20
##   Carolea          23 187  22
##   Leccino          99 334  14
##   Picholine        53 140  60</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#marginal totals:</span>

(cultSums &lt;-<span class="st"> </span><span class="kw">rowSums</span>(olivect))</code></pre></div>
<pre><code>## Ascolana Tenera         Carolea         Leccino       Picholine 
##             140             232             447             253</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(seedSums &lt;-<span class="st"> </span><span class="kw">colSums</span>(olivect))</code></pre></div>
<pre><code>##   0   1   2 
## 204 752 116</code></pre>
<p><strong>ANSWER THE FOLLOWING QUESTIONS:</strong></p>
<p>1D) State the null and alternative hypotheses.</p>
</div>
<div id="part-2-expected-frequencies" class="section level3">
<h3><span class="header-section-number">1.8.3</span> Part 2: Expected Frequencies</h3>
<p>We have a table of our observed frequencies, but how do we calculate what we would have expected if No.Seeds is independent of cultivar type? Under the <span class="math inline">\(H_{0}\)</span>, we would expect the joint probability of each cell in our contingency table to be based on the probability of two independent “events” (represented by the row and column categories) happening together. The probability of two independent events occuring simultaneously is simply the multiplication of the probabilities of each independent event. For example, if <span class="math inline">\(H_{0}\)</span> is true, the probability that an olive fruit randomly sampled from this population of olive plants is both an Ascolana Tenera cultivar <strong>and</strong> contains 2 seeds is equal to the probability of being an Ascolana Tenera cultivar type multiplied by the probability of having 2 seeds. We estimate these probabilities using the marginal totals we calculated above divided by the total number of plants we sampled.</p>
<p>2A) Calculate the marginal probabilities of each variable attribute. 2B) Using the marginal probabilities from 2A, create a table of expected joint probabilities for each combination of cultivar type and number of seeds.<br />
2C) Using the joint probabilities from 2B, calculate the expected frequencies of each combination of cultivar type and number of seeds.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#First, calculate the total number of olive fruits used in this study:</span>

(total &lt;-<span class="st"> </span><span class="kw">sum</span>(cultSums)) <span class="co">#or</span></code></pre></div>
<pre><code>## [1] 1072</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">total &lt;-<span class="st"> </span><span class="kw">nrow</span>(olives)

<span class="co">#2A:</span>
<span class="co">#Calculate the marginal probabilities of being a particular cultivar type:</span>

(cultp &lt;-<span class="st"> </span>cultSums<span class="op">/</span>total)</code></pre></div>
<pre><code>## Ascolana Tenera         Carolea         Leccino       Picholine 
##       0.1305970       0.2164179       0.4169776       0.2360075</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Calculate the marginal probabilities of having a certain number of seeds:</span>

(seedp &lt;-<span class="st"> </span>seedSums<span class="op">/</span>total)</code></pre></div>
<pre><code>##         0         1         2 
## 0.1902985 0.7014925 0.1082090</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#2B:</span>
<span class="co">#Fill a table with the calculated joint probabilities for each combination of cultivar and number of seeds:</span>

##Copy the dimensions of the cont. table to a new table.  We will do this by simply copying the original contingency table, then replacing the original observed frequencies with joint probabilities:

jprobs &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(olivect)

<span class="co">#Fill the &quot;Ascolana Tenera&quot; cultivar row with joint probabilities by multiplying the marginal &quot;Ascolana Tenera&quot; probability by all the marginal  probabilities from seedp.  Since the probabilities from seedp are in the same order as the jprobs columns, this will work fine:</span>

jprobs[<span class="st">&quot;Ascolana Tenera&quot;</span>, ] &lt;-<span class="st"> </span>cultp[<span class="st">&quot;Ascolana Tenera&quot;</span>] <span class="op">*</span><span class="st"> </span>seedp

<span class="co">#Do the same for the other four cultivar types:</span>

jprobs[<span class="st">&quot;Carolea&quot;</span>, ] &lt;-<span class="st"> </span>cultp[<span class="st">&quot;Carolea&quot;</span>] <span class="op">*</span><span class="st"> </span>seedp
jprobs[<span class="st">&quot;Leccino&quot;</span>, ] &lt;-<span class="st"> </span>cultp[<span class="st">&quot;Leccino&quot;</span>] <span class="op">*</span><span class="st"> </span>seedp
jprobs[<span class="st">&quot;Picholine&quot;</span>, ] &lt;-<span class="st"> </span>cultp[<span class="st">&quot;Picholine&quot;</span>] <span class="op">*</span><span class="st"> </span>seedp

<span class="co">#2C:</span>
<span class="co">#Calculate the expected frequencies based on the joint probabilities under the null hypothesis multiplied by the total number of fruits sampled.  </span>

(oliveExp &lt;-<span class="st"> </span>jprobs <span class="op">*</span><span class="st"> </span>total)</code></pre></div>
<pre><code>##                  No.Seeds
## cultivar                  0         1         2
##   Ascolana Tenera  26.64179  98.20896  15.14925
##   Carolea          44.14925 162.74627  25.10448
##   Leccino          85.06343 313.56716  48.36940
##   Picholine        48.14552 177.47761  27.37687</code></pre>
<p><strong>ANSWER THE FOLLOWING QUESTIONS:</strong></p>
<p>2D) Explain in your own words how we use probability theory to calculate expected frequencies if number of seeds was independent of cultivar type.</p>
</div>
<div id="part-3-calculate-chi2" class="section level3">
<h3><span class="header-section-number">1.8.4</span> Part 3 Calculate <span class="math inline">\(\chi^{2}\)</span></h3>
<p>The <span class="math inline">\(\chi^{2}\)</span> values are calculated from the square of the differences between the observed and expected frequencies, weighted by the expected frequencies.</p>
<p>3A) Use the following formula to calculate the <span class="math inline">\(\chi^{2}\)</span> test statistic for our contigency table:</p>
<p><span class="math display">\[\chi^{2} = \Large\Sigma \space\small\frac{(observed - expected)^2} {expected}\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Calculate chi square values for each cell:</span>

(chisqtable &lt;-<span class="st"> </span>(olivect <span class="op">-</span><span class="st"> </span>oliveExp)<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>oliveExp)</code></pre></div>
<pre><code>##                  No.Seeds
## cultivar                   0          1          2
##   Ascolana Tenera  0.2087378  0.5291680  1.5531946
##   Carolea         10.1313362  3.6144822  0.3839069
##   Leccino          2.2833302  1.3314557 24.4215514
##   Picholine        0.4894734  7.9140765 38.8747531</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(chisq &lt;-<span class="st"> </span><span class="kw">sum</span>(chisqtable))</code></pre></div>
<pre><code>## [1] 91.73547</code></pre>
<p><strong>ANSWER THE FOLLOWING QUESTIONS:</strong></p>
<p>3B) Looking at the chisqtable table object that holds individual <span class="math inline">\(\chi^{2}\)</span> values, are there any cultivar/No.Seeds combinations that stand out as particularly different from what we would have expected under <span class="math inline">\(H_{0}\)</span>? How did you determine this?<br />
3C) What was the direction of difference between the observed and expected frequencies in the the cells you named for 3B? Based on this observation, if it is desirable to have more seeds per olive because this yields a larger fruit with a higher pulp/pit ratio <span class="citation">[@PierantozziPierluigi2012PaCI]</span>, what cultivar(s) would you recommend to olive farmers to maximize profits?</p>
</div>
<div id="part4-results" class="section level3">
<h3><span class="header-section-number">1.8.5</span> Part4 Results</h3>
<p>4A) Calculate the degrees of freedom 4B) Calculate the critical <span class="math inline">\(\chi^{2}\)</span> value 4C) Obtain the p value 4D) Use a built in R function to do a test of independence</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Calculate the degrees of freedom</span>
j &lt;-<span class="st"> </span><span class="kw">nrow</span>(olivect); k  =<span class="st"> </span><span class="kw">ncol</span>(olivect)
df &lt;-<span class="st"> </span>(j<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>(k<span class="op">-</span><span class="dv">1</span>)

<span class="co">#Calculate the critical value</span>
(crit &lt;-<span class="st"> </span><span class="kw">qchisq</span>(<span class="fl">0.95</span>, df))</code></pre></div>
<pre><code>## [1] 12.59159</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Is our test statistic equal to or greater than our critical value?</span>
chisq <span class="op">&gt;=</span><span class="st"> </span>crit</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#You could also simply get the p value to use as your decision rule:</span>
(pvalue &lt;-<span class="st"> </span><span class="kw">pchisq</span>(chisq, df, <span class="dt">lower.tail =</span> F))</code></pre></div>
<pre><code>## [1] 1.320725e-17</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#We just performed a test of independence by hand, but R actually has a single function that will do it all at once for you:</span>
<span class="kw">chisq.test</span>(olivect)</code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  olivect
## X-squared = 91.735, df = 6, p-value &lt; 2.2e-16</code></pre>
<p><strong>ANSWER THE FOLLOWING QUESTIONS:</strong></p>
<p>4E) Write a conclusion. Include the test statistic, p value, whether or not you reject the null hypothesis, and a statement or two about what you would recommend to olive producers based on these results.</p>
</div>
<div id="animal-sciences" class="section level3">
<h3><span class="header-section-number">1.8.6</span> Animal Sciences</h3>
<p>We can use the <span class="math inline">\(\chi^{2}\)</span> distribution to test for a relationship between two categorical variables. This type of test is called a <em>test of independence</em>. We specifically test the null hypothesis that there is statistical independence between the two categorical variables. A sample of 111 mice was divided into three groups, 57 that received a standard dose of pathogenic bacteria followed by antiserum, 58 that received the same dose of bacteria, followed by an experimental treatment, and a control group of 54 that received the bacteria, but no treatment. After sufficient time had elapsed for an incubation period and for the disease to run its course, 45 dead mice and 124 survivors were counted. Of those that died, 13 had received bacteria and antiserum, 7 had received the experimental treatment, while 25 had received bacteria only. A question of interest is if the antiserum had in any way protected the mice so that there were proportionally more survivors in that group.</p>
<p>To perform this test of independence, we will (1) create a contingency table, (2) calculate the frequencies we would expect to observe if cultivar type and number of seeds are independent, (3) calculate a <span class="math inline">\(\chi^{2}\)</span> test statistic that contains information about the deviation of our observations from what is expected under <span class="math inline">\(H_{0}\)</span> , and finally (4) compare the <span class="math inline">\(\chi^{2}\)</span> test statistic against the critical <span class="math inline">\(\chi^{2}\)</span> value to decide if we reject or fail to reject <span class="math inline">\(H_{0}\)</span></p>
</div>
<div id="part-1-create-contingency-table-1" class="section level3">
<h3><span class="header-section-number">1.8.7</span> Part 1 Create contingency table</h3>
<p>The first step in performing a test of independence is to build a <em>contingency table</em> with j rows and k columns. One variable is classed into j factor levels in the rows, and the second variable is classed into k factor levels in the columns. The frequencies of each combination of attributes between the two variables fill the table and are used to calculate the marginal totals for each attribute.</p>
<p>1A) Read in the mice data set as a csv file 1B) Create a contingency table using the table() function.<br />
1C) Calculate the marginal totals of each attribute type of each of the two variables.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mice &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;./Datasets/mice.csv&quot;</span>)

##use table() to calculate the frequencies of each treatment/result combination in the data. 
(micect &lt;-<span class="st"> </span><span class="kw">table</span>(mice))</code></pre></div>
<pre><code>##               survive
## treatment      alive dead
##   antiserum       44   13
##   control         29   25
##   experimental    51    7</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#marginal totals:</span>

(treatSums &lt;-<span class="st"> </span><span class="kw">rowSums</span>(micect))</code></pre></div>
<pre><code>##    antiserum      control experimental 
##           57           54           58</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(survSums &lt;-<span class="st"> </span><span class="kw">colSums</span>(micect))</code></pre></div>
<pre><code>## alive  dead 
##   124    45</code></pre>
<p><strong>ANSWER THE FOLLOWING QUESTIONS:</strong></p>
<p>1D) State the null and alternative hypotheses.</p>
</div>
<div id="part-2-expected-frequencies-1" class="section level3">
<h3><span class="header-section-number">1.8.8</span> Part 2: Expected Frequencies</h3>
<p>We have a table of our observed frequencies, but how do we calculate what we would have expected if the survival of mice is independent of treatment? Under the <span class="math inline">\(H_{0}\)</span>, we would expect the joint probability of each cell in our contingency table to be based on the probability of two independent “events” (represented by the row and column categories) happening together. The probability of two independent events occuring simultaneously is simply the multiplication of the probabilities of each independent event. For example, if <span class="math inline">\(H_{0}\)</span> is true, the probability that a mice randomly sampled from this population of olive plants would receive the control treatment <em>and</em> remain alive is equal to the probability of receiving the control treatment multiplied by the probability of remaining alive. We estimate these probabilities using the marginal totals we calculated above, divided by the total number of mice we sampled.</p>
<p>2A) Calculate the marginal probabilities of each variable attribute. 2B) Using the marginal probabilities from 2A, create a table of expected joint probabilities for each combination of treatment type and survival outcome.<br />
2C) Using the joint probabilities from 2B, calculate the expected frequencies of each combination of treatment type and survival outcome.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#First, calculate the total number of mice used in this study:</span>

(total &lt;-<span class="st"> </span><span class="kw">sum</span>(treatSums)) <span class="co">#or</span></code></pre></div>
<pre><code>## [1] 169</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">total &lt;-<span class="st"> </span><span class="kw">nrow</span>(mice)

<span class="co">#2A:</span>
<span class="co">#Calculate the marginal probabilities of getting a particular treatment:</span>

(treatp &lt;-<span class="st"> </span>treatSums<span class="op">/</span>total)</code></pre></div>
<pre><code>##    antiserum      control experimental 
##    0.3372781    0.3195266    0.3431953</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Calculate the marginal probabilities of surviving or not:</span>

(survp &lt;-<span class="st"> </span>survSums<span class="op">/</span>total)</code></pre></div>
<pre><code>##     alive      dead 
## 0.7337278 0.2662722</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#2B:</span>
<span class="co">#Fill a table with the calculated joint probabilities for each combination of treatment type and survival outcome:</span>

##Copy the dimensions of the cont. table to a new table.  We will do this by simply copying the original contingency table, then replacing the original observed frequencies with joint probabilities:

jprobs &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(micect)

<span class="co">#Fill the &quot;antiserum&quot; treatment row with joint probabilities by multiplying the marginal &quot;antiserum&quot; probability by all the marginal  probabilities from survp.  Since the probabilities from survp are in the same order as the jprobs columns, this will work fine:</span>

jprobs[<span class="st">&quot;antiserum&quot;</span>, ] &lt;-<span class="st"> </span>treatp[<span class="st">&quot;antiserum&quot;</span>] <span class="op">*</span><span class="st"> </span>survp

<span class="co">#Do the same for the other treatment type:</span>

jprobs[<span class="st">&quot;experimental&quot;</span>, ] &lt;-<span class="st"> </span>treatp[<span class="st">&quot;experimental&quot;</span>] <span class="op">*</span><span class="st"> </span>survp

jprobs[<span class="st">&quot;control&quot;</span>, ] &lt;-<span class="st"> </span>treatp[<span class="st">&quot;control&quot;</span>] <span class="op">*</span><span class="st"> </span>survp


<span class="co">#2C:</span>
<span class="co">#Calculate the expected frequencies based on the joint probabilities under the null hypothesis multiplied by the total number of mice sampled.  </span>

(miceExp &lt;-<span class="st"> </span>jprobs <span class="op">*</span><span class="st"> </span>total)</code></pre></div>
<pre><code>##               survive
## treatment         alive     dead
##   antiserum    41.82249 15.17751
##   control      39.62130 14.37870
##   experimental 42.55621 15.44379</code></pre>
<p><strong>ANSWER THE FOLLOWING QUESTIONS:</strong></p>
<p>2D) Explain in your own words how we use probability theory to calculate expected frequencies if survival outcome was independent of treatment type.</p>
</div>
<div id="part-3-calculate-chi2-1" class="section level3">
<h3><span class="header-section-number">1.8.9</span> Part 3 Calculate <span class="math inline">\(\chi^{2}\)</span></h3>
<p>The <span class="math inline">\(\chi^{2}\)</span> values are calculated from the square of the differences between the observed and expected frequencies, weighted by the expected frequencies.</p>
<p>3A) Use the following formula to calculate the <span class="math inline">\(\chi^{2}\)</span> test statistic for our contigency table:</p>
<p><span class="math display">\[\chi^{2} = \Large\Sigma \space\small\frac{(observed - expected)^2} {expected}\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Calculate chi square values for each cell:</span>

(chisqtable &lt;-<span class="st"> </span>(micect <span class="op">-</span><span class="st"> </span>miceExp)<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>miceExp)</code></pre></div>
<pre><code>##               survive
## treatment          alive      dead
##   antiserum    0.1133737 0.3124076
##   control      2.8472576 7.8457764
##   experimental 1.6753732 4.6165839</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(chisq &lt;-<span class="st"> </span><span class="kw">sum</span>(chisqtable))</code></pre></div>
<pre><code>## [1] 17.41077</code></pre>
<p><strong>ANSWER THE FOLLOWING QUESTIONS:</strong></p>
<p>3B) Looking at the chisqtable table object that holds individual <span class="math inline">\(\chi^{2}\)</span> values, are there any treatment/survival outcome combinations that stand out as particularly different from what we would have expected under <span class="math inline">\(H_{0}\)</span>? How did you determine this?<br />
3C) What was the direction of difference between the observed and expected frequencies in the the cells you named for 3B? Based on this observation, what treatment type would you recommend to control the pathogenic bacteria?</p>
</div>
<div id="part4-results-1" class="section level3">
<h3><span class="header-section-number">1.8.10</span> Part4 Results</h3>
<p>4A) Calculate the degrees of freedom 4B) Calculate the critical <span class="math inline">\(\chi^{2}\)</span> value 4C) Obtain the p value 4D) Use a built in R function to do a test of independence</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Calculate the degrees of freedom</span>
j &lt;-<span class="st"> </span><span class="kw">nrow</span>(micect); k  =<span class="st"> </span><span class="kw">ncol</span>(micect)
df &lt;-<span class="st"> </span>(j<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>(k<span class="op">-</span><span class="dv">1</span>)

<span class="co">#Calculate the critical value</span>
(crit &lt;-<span class="st"> </span><span class="kw">qchisq</span>(<span class="fl">0.95</span>, df))</code></pre></div>
<pre><code>## [1] 5.991465</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Is our test statistic equal to or greater than our critical value?</span>
chisq <span class="op">&gt;=</span><span class="st"> </span>crit</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#You could also simply get the p value to use as your decision rule:</span>
(pvalue &lt;-<span class="st"> </span><span class="kw">pchisq</span>(chisq, df, <span class="dt">lower.tail =</span> F))</code></pre></div>
<pre><code>## [1] 0.000165691</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#We just performed a test of independence by hand, but R actually has a single function that will do it all at once for you:</span>
<span class="kw">chisq.test</span>(micect)</code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  micect
## X-squared = 17.411, df = 2, p-value = 0.0001657</code></pre>
<p><strong>ANSWER THE FOLLOWING QUESTIONS:</strong></p>
<p>4E) Write a conclusion. Include the test statistic, p value, whether or not you reject the null hypothesis, and a statement or two about what recommendations you would make based your results.</p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
