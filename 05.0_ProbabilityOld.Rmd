# Probability in Applied Statistics {#chProb}

See probability_cheat sheet.pdf
See Appendix A of KNN book.
See Introductory Statistics with R.
See Distributions Oct 6, 2017 in Notability
Constant, Random variable and Random number. PSAES ch. 6
Permutations, combinations. See PSAES.pdf.
Types of random variables.
Distributions of random variables. Discrete. Continuous.
Distributions of functions of random variables.
Mean, variance, covariance vs. parameters of distributions. Examples: Normal and Student's t.



## Learning Objectives for Chapter

1. Define random variables and their distributions.
1. Define probability and list the main probability "laws."
1. Determine if a process is random or deterministic and give examples of both.
1. Given a random experiment like rolling a die, write down the sample space.
1. Determine the probability mass function of a given random experiment.
1. List multiple causes that determine the outcome of a random experiment.
1. Define "parameter."
1. Classify a list of quantities as values of random variables or parameters.
1. Define "independence" in the context of probability events and determine if two events are independent.
1. Explain what conditional probability is with a diagram and with formulas.
1. Calculate the probability of:
 - 1 of 2 mutually exlusive events occurring (either/or)
 - two events occuring that are independent
 - the probability of one event occuring, given that another event has already occurred.  
1. Write down Bayes rule and define each of its components.
1. Apply Bayes rule to minimize error rate in classification of a plant as annual or perennial.
1. List the most important distributions in elementary statistics.
1. Plot and describe the main features of the statistical distributions.
1. Give examples of processes that generate random variables with the most important distributions.
1. State the central limit theorem and show its effects with a simulation.
1. State the relationship among normal, Student's t, $\chi^2$ and F distributions.




## Variables and parameters

The terms "variable" and "parameter"" should be defined and used carefully. People frequently and incorrectly use the term "parameter" to refer to variables. This makes things more confusing.

Do not confuse "moments"" with parameters. The $\chi^2$, t and F distributions can be used as good example of the difference between moments and parameters. The parameters are degrees of freedom, whereas some of their moments are determined by, but different from, the degrees of freedom.

**Parameters** are constants that determine the statistical distribution of random variables and thus, characterize populations. Usually, *parameters* cannot be measured directly and they cannot be known with certainty unless the whole population is known. The value of a parameter is not necessarily represented in the population values of the variable. For example, the mean, as a parameter, may not be similar to any of the values in the population. A clear case is the Bernoulli distribution, where the population is composed of 1's and 0's and the mean is a number between 0 and 1.

**Variables** may take a different value for each member of the population and can be measured directly and with certainty, within the precision of the measuring instrument.

Consider the following example. We define a random variable $X$ as the sum of the number of dots and the number of heads when we simultaneously roll a die and flip two coins. Assume that for each object (die, coin A, coin B) all outcomes are equally probable. This random experiment generates a probability distribution for $X$. This distribution has a mean, which we still do not know, ...


### What does "random" mean?

Processes or experiments that have outcomes can be random or deterministic. When the outcome of a process is not known beforehand, we will say that the process and the resulting outcomes are random. For example, the number that will be selected in a roulette is random. The day of the week tomorrow is deterministic. "A random experiment is an experiment whose outcome is uncertain. Examples include throwing a pair of dice, tossing a coin, counting the number of defectives in a sample from a lot of manufactured items, and observing the time to failure of a tube in a heat exchanger, or a seal in a pump, or a bus section in an electrostatic precipitator." [@PSAES2007].

Although we will use this definition of "random," the word "random" is used with several related but different meanings. For example, sequences of values that cannot be compressed and expressed using less memory without loss of information are also called "random," but that is not the meaning we will use in this book.


**Random** is said of experiments whose outcomes are not known with certainty. By "experiment" we mean any set of actions or processes that will result in an outcome, not just scientific experiments.^[A more restrictive definition of "experiment" is used in [Chapter 10](#chEdesign), where it refers to scientific experiments where treatments are assigned to experimental units using randomization.]


### "Just due to Chance"

We frequently encounter explanations of events where a part of the event is said to be caused by certain factors and the rest is *"just due to random chance."* This phrase can lead to misunderstanding and should be considered thoroughly. Randomness does not mean that the process could have resulted in a different outcome if **all conditions were exactly the same**. Randomness or "just chance" is used to refer to the effects of all of the variables that affected the outcome but that we did not measure or consider. 

Statements like the following are common in the literature. These were selected haphazardly because they were readily available.

"Seascale is a village 3 km to the south of Sellafield and had y = 4 cases of lymphoid malignancy among 0–14 year olds during 1968–1982, compared with E = 0.25 expected cases (based on the number of children in the region and registration rates for the overall northern region of England). A question here is whether such a large number of cases could have reasonably occurred by chance. There is substantial information available on the incidence of childhood leukemia across the United Kingdom as a whole." [@Wakefield2013]

"Exploratory studies are often informal in nature, and many different models may be fitted in order to gain insights into the structure of the data. In general, however, great care must be taken with data dredging since spurious associations may be discovered due to chance alone." [@Wakefield2013]

"However, Le et al. (1999) argue for including those effects nonetheless. For one thing, they may point to potential hot-spots. These can be due to unknown environmental hazards or known ones that have simply not been detected. Just such spots were seen around the Rocky Mountain Arsenal described in Example 1.2. Of course apparent hot-spots can be artifacts of chance variation so confirmation is vital, a topic beyond the scope of this book." [@LeZidek2006]

"The mean winning time for the first 13 races is 2 hours, 44 minutes, and 22 seconds (written 2:44:22). The mean winning time for the second 13 races is 2:13:18. This is quite a difference (over half an hour). Does this prove that the fastest men are running faster? Or is the difference just due to chance, no more than what often emerges from chance differences in performance from year to year? We can't answer this question with descriptive statistics alone." [@Lane2018]

"The P-value reports the likelihood that the observed difference was due to chance alone. For example, if a statistical test comparing two sample means yields a P-value of 0.24 this indicates that there is a 24% chance of obtaining the observed result even if there is no true difference between the two sample means." [@ElzingaEtAl1998]

It is important to correctly interpret phrases like "due to chance" and we recommend not to use them, because they can be misleading. "Due to chance" may be interpreted as "due to a very specific combination of conditions and causes that we are not interested in at this time." Be careful not to just accept the statement as meaning that many different results could have been possible under the same conditions. The randomness of all results is just due to the fact that we cannot, or choose not to, measure all the relevant variables and processes that lead to a result. In the case of the comment about data dredging above, the phrase "due to chance alone" can be interpreted as meaning that the association detected is not a property of the population about which the scientist wants to make statements.

For example, consider the number of tweets so that each student has sent in the last day. For an investigator interested in the population of students, perhaps the variation from student to student can be considered to be random and have some sort of statistical distribution for random errors. However, for each individual student the number of tweets they made is a known quantity and it is not considered to be an error in any way, not even in a statistical way. Presumably, students know exactly why they sent each tweet and the number of tweets for a particular day.


## Probability

We need to use the concept of probability in order to be able to express and quantify uncertainty. Significance and confidence levels used in statistical statements are measures of probability, and they must be assigned or calculated in a manner that is consistent with the theory of probability. The theory of probability is a branch of mathematics that provides all the tools we need to operate with probabilities. By linking a real-world phenomenon with a probability model, we can use probability theory to derive new practical results that help us in the real world. For example, we can calculate the probability of incorrectly rejecting a null hypothesis, or the probability that an investment will yield a return greater than inflation, or the probability that a person will live more than 10 years after retirement.

```{block, type = 'mydef'}
Probabilities P are real numbers associated with random experiments that have the following properties:

* $0 \le P \le 1$ \
* If a random experiment is performed, P of some event is 1. \
* The probability of either one of two mutually exclusive events occuring is the sum of the individual probabilities.
```

Although there are several interpretations of probability in terms of what it means for the "real world," all interpretations follow the same rules for the calculus of probability.

In thinking of probability, it is important to differentiate between using the theory of probability to make calculations that are correct, and the application of the theory to assign probabilities to specific real-world outcomes. For example, the probability of obtaining a particular number by rolling a die can be assigned by rolling the die a very large number of times and calculating the proportion of times the selected number came up. In using the proportion observed in the past to characterize the die in the future, one is implicitly assuming that all conditions will remain the same. This is not always a completely safe assumption, because over time the die may wear out unevenly, and change the probabilities. The example is clearer if you think of the probability of a different event, for example, the probability that your first job after graduation will pay more than \$50,000. It is simpler to imagine the same die being rolled repeatedly, as if the universe remained constant from one roll to the next, than to imagine your life repeating many times. However, the probability model can be applied in both cases. As an exercise, write down at least two difference ways to get an estimate of the probability that you will make more than \$50,000 in your first job. This is an easter egg. Describe the problem and your proposed solution in class before anybody else and get a reward. Make sur eto claim your easer egg reward, Hint: think of yourself as one of many.

Another way to assign probabilities to experimental outcomes is by using the idea of symmetry. In the case of the die we may reason that all sides are the same and there are six sides, therefore each side gets a probability of $1/6$. In the case of flipping a coin, we assign equal probabilities to each side. We intuitively understand that the sum of the probabilities of all outcomes must be one, because one outcome must take place for each experiment. Do not confuse symmetry with lack of knowledge. The probability of all outcomes is not always the same, even if there are just two outcomes. Some people suffer from a tendency to think that if there are only two outcomes possible then "chances are 50:50." If you are asked about the probabiliy of getting a random card that is black form a deck, you should not bet on 50:50, in spite of the fact that there are only two outcomes, the card is black or it is not.



### Frequentist and Bayesian probability

You may be surprised to learn that there are two different schools of thought about the application of probabilities to real-world problems: Bayesian and Frequentist or classic. Both are useful and give almost identical results in many situations, but they have deep philosophical differences, and yield different interpretation of results in important cases. This course deals almost exclusively with the Frequentist approach, which is the most commonly used. Bayesian probability and thinking is introduced to make sure that students keep an open mind and are not blindsided when they encounter applications of Bayesian statistics in the future.

Frequentist probability of an event is the relative frequency of the event approached as the number of experiments or trials conducted in identical conditions increases without bound. The probability of obtaining a head in a coin toss is the number of heads observed divided by the total number of tosses when the number of tosses is very, very large.

In Bayesian statistics, probability is the metric used to quantify certainty. Probability of different events and randomness refer to the information we have, not to the world. A probability of 1 means that we are certain about an event, and a probability of 0 means we are certain it will not happen. The focus of Bayesian statistics is in updating the measure of certainty by using data. As more data are collected, our uncertainty is updated accordingly. Because the focus is on certainty by people, the Bayesian probability is called "subjective" and in Bayesian statistics it is meaning ful to talk about probability distributions for parameters. Because parameters are not known, people are uncertain about them, and that uncertainty is quantified by probability functions. In Bayesian statistics, parameters are treated as random variables.


### Outcomes, sample space and events

In order to have a minimal basis for working with probabilities and to be able to make statistical statements with properly quantified probabilities we need to define the elements of a **Probability Model**. Consider the roll of a die as before. The result can be 1 or 2 or 3 or 4 or 5 or 6. The set of numbers 1 to 6, all possible outcomes of the experiment, is called **sample space** and it is represented with the Greek letter capital omega $\Omega$.

<br>
\begin{equation}
\text{Sample space for rolling a 6-sided die:} \\[15pt]
\Omega=\{1,2,3,4,5,6\}
\end{equation}
<br>

However, when people use a die for gambling, they are not restricted to betting on a single number at a time. For example, one may want to bet that the number is even, or that it is either a 1 or a 3, or that it is not a 6. With the original sample space we can think of many possible events, each of which has a chance of happening. Imagine all possible events, from no number resulting from the roll (we assume for now that this is impossible if the die is rolled), to obtaining a number between 1 and 6 (a certainty). These are ALL possible events E and they are all possible subsets of $\Omega$. Because there are six numbers in the sample space and each number either is or is not in a subset the total number of event possible is $2^6 = 64$.

Finally, in order to make reasonable bets, one needs to be able to calculate the probability of each event E. We know that the probability of the empty set of the six numbers is zero, and that the probability of one number from the whole set is 1; but how do we determine the other probabilities? For this we need to complete the probability model by requiring that the probability assigned to each event follow some rules:

<br>
\begin{align}
A. \quad &0 \le P(E) \le 1 \\[20pt]
B. \quad &\text{if } \ E_1 \cap E_2 = \phi \\[10pt]
&\implies P( E_1 \cup E_2) = P(E_1) + P(E_2) \\[20pt]
C. \quad & P(\Omega) = 1
\end{align}
<br>

**A**. States that probabilities are numbers between 0 and 1 (including 0 and 1).

**B**. The probability of the experiment resulting in either of two disjoint events is the sum of the individual probabilities. For example, the probability that a die roll will results in 3 or 6 is the sum of the probability of 3 plus the probability of 6.

**C**. The probability that one of the outcomes in th esample space wil take place is 1.

Amazingly, all properties of probabilities can be derived from those axioms.

<br>
A **probability model** has three components:

1. Sample space
1. Enumeration of all possible events
1. Assigned probabilities
<br>

Such that probabilities are between 0 and 1, inclusive, and the where the probability of two mutually exclusive events is the sum of the probabilities of the individual events.

The sample space of rolling a die was given above. We will define an event as any subset of the sample space. For example "getting a 1" is the event that includes only the number 1, whereas "getting either a 1 or a 6" includes the two numbers:

\begin{equation}
  E_1 = \{1\} \quad \quad E_2= \{1,6\}
\end{equation}

Other events that we will use in the examples are:

\begin{equation}
  \text{   } E_3= \{ \} = \phi \quad \quad E_4= \{1,2,3,4,5,6\}
\end{equation}



```{r dieEvents, message=FALSE, warning=FALSE, paged.print=FALSE, out.width = '60%', fig.align='center', echo=FALSE, fig.cap ="Sample space of rolling a 6-sided die and events marked as subsets of the sample space."}

knitr::include_graphics("images/Events01.jpg")

```

Consider a second random experiment: draw a random card from a standard deck of playing cards. The deck has 52 cards, 13 of each suit, 26 of each color. We are interested in the probabilities associated with various events. What will be extremely difficult for most of us in dealing with probabilities of "card events" is routine for professional card players.

First, let us think about the problem of creating a probability model for the deck of cards. The most basic question is: what probability do we assign to each card?! From the frequentist point of view, we would have to sample the cards manby many times and assign to each card the relative frequency observed. As with the multiple rolls of a die mentioned before, we would question the preconception that probabilities will remain constant over time. They would not, because cards would wear our diferently. We could get a lot of decks and take just on card from each deck, but this would not give us the probability for any specific deck. We choose to use the "symmetry" point of view, where we assume that there is nothing different about picking any of the 52 cards. Therefore they all have to have equal probability. The sample space is each of the 52 cards, and each outcome is given a probability of 1/52. Given this, we know have all we need to know the probability of any event exactly. The probability is exact because we (assume that we) know the "true" distribution. As we will see later, this is not the case in most of the real experimental work. Most real-world situations we would not know the 

Now we can define events and consider their probabilities. The following are all events, or subsets of the sample space:

1. Ace
1. Even
1. Red or Even
1. Red and Even, or prime

In each case, the probability equals the total number of favorable cases divided by the total number of possible cases, which is 52. P(Ace) = 4/52, P(Even) = 20/52, P(Red or Even) = P(Red) + P(Even) - P(Red and Even) = (13 + 20 - 10)/52. In the last case we subtracted Red and Even to avoid double-counting them as Red and as Even. Two difficulties may arise in trying to calculate the probabilities of these events: calculation of the total number of outcomes, calculation of the total number of favorable events. For these concepts and calculations it is useful to learn about Combinatorics and Set Theory.

### Combinatorics

This is just the most basic introduction to those aspects of combinatorics that will be used in the course. Combinatorics is the branch of mathematics that deals with counting, ordering and arranging sets of objects of elements. For example, how many different sets of 4 cards can you obtain from a deck if you draw them with and without replacement? The probability of getting any specific ordered set would be the reciprocal of such number. It turns out that the number is $52^4$ with replacement and $52! / (52 - 4)!$ without replacement. The "!" means "**factorial**" and consists of the product of all natural numbers that are equal or smaller than the number to the left of the symbol.

<br>
\begin{align}
&\text{Factorial} \\[20pt]
k! &= k \ \cdot \ (k - 1)! \\[15pt]
0! &= 1
\end{align}
<br>

Thus, $52! / (52 - 4)! = 52\cdot 51 \dots 2 \cdot 1 / (48 \cdot 47 \dots 2 \cdot 1 =  52\cdot 51 \cdot 50 \cdot 49$. This is the number of different *permutations* of 52 cards taken in sets of 4, without replacement. But what is we drew more cards or if the order of the cards did not matter? Combinatorics has all of this organized for you, and it provides us with the formulas to calculate the necessary numbers for any situation. But first, we need to define the kinds of counting situations we have.

Consider that you have 5 objects or options, say A, B, C, D and E. These could be 5 cards, or 5 activities to choose from or anything else. For now, just think of them as 5 letters. We can make sequences of letters containing just those 5 letters. The order of the letters may or may not matter and the sequences can be made with or without replacement. If order matters we are dealing with **permutations** and if order does not matter, we are dealing with **combinations**.

```{block, type='mydef'}
If $AB \ne BA$ it's Permutations (order matters).
If $AB = BA$ it's Combinations (order does not matter).
```

Therefore, there are four cases for getting sequences of r objects taken from a set of n:

- permutations without replacement $P(n,r) = P(^n_r)$,
- permutations with replacement $PR(n,r) = PR(^n_r)$,
- combinations without replacement $C(n,r) = C(^n_r) = (^n_r)$,
- combinations with replacement $CR(n,r) = CR(^n_r)$.

The most common situation we will encounter in this course is that of combinations without replacement. We will use it primarily in the calculations for **binomial distributions**.

**Permutations withou replacement**



In the binomial calculations, the combinations are combinations of positions where "success" happens. We use combinations because having "success" in positions 1 and 5 for example, is exactly the same as having success in position 5 and 1. This is a bit perverse. Just note that the order of successes and failures matters but the order of the positions of the successes and failures does not! Coins tosses HHTT are not the same as HTHT. However, having H in positions 1 and 2 is the same as having H in positions 2 and 1. To one of the authors (EAL) this is a bit mind bending, but not too much.



### Conditional probability and independence

Some important definitions of certain events are necessary.

**Probability as long-run relative frequency**: If we can imagine that an experiment or random process can be repeated under identical conditions a very large number of times, the relative frequency observed for a specific event tends to equal the probability of the event as the number of repetitions increases.

**Conditional Probability**: The conditional probability of one event given that another event is known to have happened is defined as the probability of the intersection of the two events divided by the probability of the event known to have happened.

$$P(E_1|E_2) = P(E_1 \cap E_2) / P(E_2)$$

Using the events defined above we can calculate the probability of getting a 6 given that we know that either a 1 or a 6 was rolled. By arguments of symmetry we have assigned a probability of $\frac{1}{6}$ to each event consisting of a single number. Thus, the probability of event $E_1$ is $\frac{1}{6}$, and the probability of event $E_2$ is $\frac{2}{6}$. The intersection of the two events is the number 6 that they have in common, $E_1 \cap E_2 = \{6\}$, so the probability of the intersection is also $\frac{1}{6}$ and the resulting conditional probability is $\frac{1}{2}$, which should make intuitive sense: given that either a 1 or a 6 was observed, what is the probability that it was a 1? It's a 50:50 chance.

<br>
$$E_1 \cap E_2 = \{6\} \implies P(E_1 \cap E_2) = P(\{6\}) = \frac{1}{6}$$
<br>

$$P(E_2) = P(\{1,6\}) = \frac{2}{6}$$
<br>

Therefore, 

<br>
$$P(E_1|E_2) = \frac{\frac{1}{6}}{\frac{2}{6}} = \frac{1}{2}$$
<br>

**Independent events**: We say that two events are independent if the probability of observing both events simultaneously is the product of the probabilities of each event separately. More intuitively, if two events are independent, by knowing one of them you gain no information about the other one. In other words, one event does not affect the probability of the other one.

Do not confuse independent event with the concepts or terms dependent and independent variables that we will use later in the course.

For example, annual grasses have roots that are smaller than perennial grasses, and therefore, it is easier to uproot them. The problem is that young perennial plants also have small roots.  Suppose that it is estimated that about 10\% of the perennial grasses in a field are young, and 50\% of all the grass plants in the field are perennial. All annual grasses can be uprooted easily. The experiment we conduct is to uproot a randomly selected plant and determine if it was easy. In order to determine the probability, imagine that there are 1000 plants and that we uproot them all one at a time. We will find that in 550 cases the uprooting was easy: the 500 annual plants and the 50 young perennial plants were easy to uproot. The situation is represented in the following table.


\begin{center}
  \begin{tabular}{llr}
  \hline
  \multicolumn{3}{r}{Uprooting is} \\
  \cline{2-3}
  Lifespan    & Easy & Hard \\
  \hline
  Annual      & 500    & 0      \\
  Perennial   & 50     & 450      \\
  \hline
  \end{tabular}
\end{center}


If the uprooting is easy, the probability that the plant is perennial is 50/550, whereas when the uprooting is hard the probability of perennial is 450/450. Therefore, these events are not independent. By determining if the plant is hard to uproot we can greatly increase our certainty about its lifespan.  However, as we will see later, the meaning of the information obtained depends on other pieces of information (hint: the prior probability). Let's write the probabilities suing equations:

\begin{equation}
  P(annual) = 500/1000 \quad \quadP(perennial = 500/1000) \quad \quad
\end{equation}

\begin{equation}
  P(Easy) = 550/1000 \quad \quadP(Hard) = 450/1000 \quad \quad
\end{equation}

\begin{equation}
  P(Easy \cap perennial) = 50/1000 \quad \quadP(Hard \cap annual) = 0/1000
\end{equation}

\begin{equation}
  P(Easy) P(perennial) = (550/1000) (500/1000) = 225/1000 \neq P(Easy \cap perennial)
\end{equation}

One the product of the probabilities of each event is not equal to the probability of both events occurring simultaneously, therefore, the events are NOT independent.

Note that in this example of perennial and annual plants there is an obvious biophysical mechanism linking the events to each other: annual plants have smaller roots than most perennial plants, and therefore they are easier to uproot than most perennial plants. Annual roots are smaller because they are needed for and can grow during just one season. A lot of science and statistics deals with detecting lack of independence and finding out the mechanisms that are behind the lack of independence. Keep in mind that lack of independence does not mean that there is cause-and-effect relationship among events. Playing basketball will not make kids taller, at least not taller than they can become by any other type of systematic exercise and good diet.

## Bayesian and Frequentist approaches

### Were you selected at random?

 Chris Westbury (Bayes For Beginners, accessed 8 June 2015,
https://www.ualberta.ca/~chrisw/BayesForBeginners.pdf) wrote:
"A particular disorder has a base rate occurrence of 1/1000 people. A test to detect this disease has a false positive rate of 5\% that is, 5\% of the time that it says a person has the disease, it is mistaken. Assume that the false negative rate is 0\% the test correctly diagnoses every person who does have the disease. What is the chance that a randomly selected person with a positive result actually has the disease?
When this question was posed to Harvard University medical students, about half said that the answer was 95\%, presumably because the test has a 5\% false positive rate. The average response was 56\%. Only 16\% gave the correct answer, which can be computed with Bayes Rule in the following manner:"

\begin{equation}
  P(\text{Disease}) = 0.001\text{  probability of a random person being sick}
\end{equation}

The total (marginal) probability of having a positive test is the sum of all independent ways to get a positive test, which includes getting a positive when having the disease (true positive) and getting a positive when not having the disease (false positive).

\begin{equation} \label{eq:tot_prob_exmpl1}
  P(Positive) = P(+) = P(True+) + P(False+)
\end{equation}

The probability of getting a true positive is the probability of being sick and getting a positive \textbf{given that} one has the disease.

\begin{equation}
  P(True+) = P(+ \text{ \& Disease}) = P(\text{Disease}) P(+ | \text{Disease}) = 0.001 * 1.0
\end{equation}

\begin{equation}
  P(False+) = P(+ \text{ \& No Disease}) = P(\text{Disease}) P(+ | \text{ No Disease}) = 0.999 * 0.05
\end{equation}

\begin{equation}
  P(+) = (0.001 * 1.0) + (0.999 * 0.05) = \Sexpr{(0.001 * 1.0) + (0.999 * 0.05)}
\end{equation}

\begin{equation}
  P(\text{Disease} | +) = \frac{P(\text{Disease}) * P(+ | \text{Disease})}{P(+)} = 0.001 * 1.0 / 0.051 = \Sexpr{round(0.001 * 1.0 / 0.051, 4)}
\end{equation}



\begin{center}
  \begin{tabular}{llrr}
  \hline
  \multicolumn{3}{r}{Disease} \\
  \cline{2-3}
  Test   & Yes    & No       & Total \\
  \hline
  +      & 10     & 500      & 510   \\
  -      &  0     & 9490    & 9490   \\
  \hline
  Total  & 10     & 9990    & 10000  \\
  \end{tabular}
\end{center}



% ADD VISUAL REPRESENTATION OF TOTAL AND CONDITIONAL PROBABILITIES. See Notability files.
% USE A 2X3 TABLE.

<<prob01, echo=FALSE, results='asis'>>=
tbl01 <- data.frame(Test = c("+", "-", "+", "-"), Disease = c("Yes", "Yes", "No", "No"), n = c(10, 0, 500, 9490))
@

% ADD EXAMPLES OF CONDITIONAL PROBABILITY USING NORMAL DISTRIBUTION AFTER LECTURE ON NORMAL DISTRIBUTION.

"Although the test is highly accurate, it in fact gives a correct positive result just 2\% of the time. How can this be? The answer (and the importance of Bayes Rule in diagnostic situations) lies in the highly skewed base rates of the disease. Since so few people actually have the disease, the probability of a true positive test result is very small. It is swamped by the probability of a false positive result, which is fifty times larger than the probability of a true positive result.

You can concretely understand how the false positive rate swamps the true positive rate by considering a population of 10,000 people who are given the test. Just 1/1000th or 10 of those people will actually have the disease and therefore a true positive test result. However, 5\% of the remaining 9990 people, or 500 people (499.5), will have a false positive test result. So the probability that a person has the disease given that they have a positive test result is 10/510, or 2\%."

The key phrase in the statement of the problem is "randomly selected person." It is important to understand that a person was randomly selected and then administered the test. Alternatively, as Westbury explains at the end, one can think of the whole population being tested. If the person is not randomly selected from the whole population, then the calculation is not correct. The base rate used has to be based on the population from which the person was selected. It is reasonable to think that if the person was selected as a result of a consultation with a doctor, her base rate is probably greater than the base rate for the whole population. The reason for having a test matters in assessing the probability of having a disease based on the test results. A Bayesian approach to inference is particularly useful here and it is explained in the next subsection.

### Bayesian approach

The previous example of assessing the probability of having a disease based on imperfect test results is an example of Bayesian statistics. The probability is estimated using Bayes Rule directly. In abstract form, Bayes Rule states:


\begin{equation}
P(A|B) = \frac{P(A) * P(B|A)}{P(B)}
\end{equation}\\


Recall that the vertical bar is read as "given," "given that," or "conditional on."
In Bayesian statistics, the rule is applied with special meaning for each component of the equation. A is the event whose probability or degree of certainty we want to determine. B is the event observed or data. In the case of the disease example above, A is "person has the disease" and B is "person tested positive." The probability of having the disease P(A) is the knowledge \emph{prior} to taking the test, the probability that any randomly selected person has the disease. Note that this is prior knowledge and it may or may not be available. In the example the information is available based on previous studies: $P(A) = P(Disease) = 0.001$. Because it is the knowledge available before obtaining new data, the probability is known as \emph{prior probability} or simply \emph{prior}. P(B) is the total probability of getting a positive test result. The total probability can be calculated using the law of total probability as applied in equation~\ref{eq:tot_prob_exmpl1}.


\begin{equation} \label{eq:total-probability_discrete}
P(A) = \displaystyle\sum_{i=1}^{n} P(A|B_i) P(B_i)
\end{equation}\\


Where $B_i \text{ with } i=\{1,\dots,n\}$ is a set of mutually exclusive ("pairwise disjoint") events that whose union is the entire sample space. For example, $B_1$ is "test is positive" and $B_2$ is "test is negative." Assuming that testing results either in positive or negative (i.e. there are no inconclusive results) there is no option left out and the whole sample space is covered. The partition is exhaustive.

In summary, the Bayesian approach updates our level of certainty about a hypothesis or unobserved event by combining prior knowledge with data. The data are taken as true and the probability of the hypothesis conditional on the data is calculated using Bayes rule.



% DEVELOP EXAMPLE FOR CLASSIFICATION OF SEEDS


### Frequentist approach

The frequentist approach does not consider the relative merit of all possible hypothesis but it estimates the probability of observing the data when the hypothesis is true. If the probability is very low, it rejects the hypothesis. It is very important to remember that the frequentist approach DOES NOT estimate the probability of the hypothesis being true or false. It only estimated the conditional probability for the data given the null hypothesis.




## Basic Statistical Distributions

See lecture "Distributions Oct 6, 2017.pdf"

### Bernoulli Distribution (#BerDist)

### Discrete Uniform Distribution (#DUnifDist)

### Continuous Uniform Distribution (#CUnifDist)

### Binomial Distribution (#BinDist)

See "BernoulliBinomial.mp4""

### Poisson Distribution (#PoisDist)

### Normal Distribution (#NormDist)

### $\chi^2$ Distribution (#chisqDist)

### Student's t Distribution (#tDist)

### F Distribution (#FDist)



## Exercises and Solutions

### Exercise 1

Objectives:

Models are approximations of reality.
Models are based on specific knowledge or assumptions.
One model assumes that a parameter is constant, but in reality the parameters can change.
More complicated models can accomodate changing parameters.

Assume that the electric motor of a water pump has a constant probability of failing in any time interval, and that on average the failure rate is once every 10,000 hours and independent of preious or future failures after repairs. 
What distribution can be used to model the number of failures in any given 1000 hour interval?

What is the probability that the motor will fail exactly once in 1000 hours?

What is the probability that it will fail at least once in 1000 hours?

Do you think the assumptions about the pump are realistic? How would you modify the assumptions to work towards a better model?

Given the potential deficiencies of the model based on the original assumptions, what errors do you expect to see as the pump get older and more time passes since the last repair?



## Homework

### Outcomes and events

Consider the three-door game described in [Chapter 1](#LearnStats). If the player chooses first the door with the car, the host will open one of the other two doors with equal probability. If the player picks a door with a goat, the host will open the other door with a goat with probability 1. List all possible sequences of outcomes of the whole process. Assume that all outcomes have equal probability at each step and calculate the following probabilites:

- Probability of getting the car when switching doors.
- Probability of getting the car when not switching door.

To facilitate the representation of outcomes, use the following sequence of letters: door with car - door selected - door shown with goat - final door chosen. The following code generates all possible sequences of outcomes. Keep in mind that the probability of the door selected by the host depends on the door selected by game player and the door behing which the car is. If the player selected door A and the car is in door B, then the host will select door C with probability equal to 1.0. In that case, the sequence of probabilities would be 1/3, 1/3, 1. This is in contrast with a sequence in which the player selects door A, the car is in door A and the host selects door B. In this case the sequence of probabilities is 1/3, 1/3, 1/2

```{r}

# Create all posible sequences, regardless of feasibility

carOrGoat <- expand.grid(carDoor = c("A", "B", "C"), 
                         choice1 = c("A", "B", "C"), 
                         goatShown  = c("A", "B", "C"),
                         switch = c("Switch", "Stay"))

# Remove unfeasible sequences

notFeasible <- with(carOrGoat, 
                    which(carDoor == goatShown | 
                          choice1 == goatShown))

carOrGoat <- carOrGoat[-notFeasible, ]

carOrGoat$finalDoor <- 
        apply(
           carOrGoat[, c("choice1", "goatShown", "switch")], 
           1, 
           function(x) if (x[3] == "Stay") x[1] else
              setdiff(c("A", "B", "C"), x[1:2])
        )

carOrGoat$result <- "Goat"

carOrGoat$result[carOrGoat$carDoor == carOrGoat$finalDoor] <- "Car"

xtabs(~ switch + result, carOrGoat)

carOrGoat[with(carOrGoat, order(carDoor, choice1, goatShown, switch, finalDoor)), ]

```

```{r, echo=FALSE, include=FALSE}

# Assignment of probabilities

carOrGoat$PcarDoor <- 1/3
carOrGoat$Pchoice1 <- 1/3
carOrGoat$PgoatShown <-
        apply(
           carOrGoat[, c("carDoor", "choice1")], 
           1, 
           function(x) if (x[1] == x[2]) 1/2 else 1)

carOrGoat$pTot <- with(carOrGoat, PcarDoor * Pchoice1 * PgoatShown)

sum(carOrGoat$pTot[carOrGoat$switch == "Switch" & 
                      carOrGoat$result == "Car"])

sum(carOrGoat$pTot[carOrGoat$switch == "Stay" & 
                      carOrGoat$result == "Car"])

```


## Laboratory Exercises

### Plant Sciences

### Animal Sciences

