---
output: 
  html_document: 
    fig_caption: yes
    number_sections: yes
    theme: readable
    toc: yes
    toc_depth: 3
---

```{r setup0, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE, paged.print=FALSE, echo=FALSE, include=FALSE}
# load packages for chapter

options(digits = 10)
library(bookdown)
library(emmeans)
library(ggplot2)
library(dplyr)
library(kableExtra)
library(knitr)
library(tables)
library(plyr)
library(pander)
library(multcomp)
library(agricolae)
library(nlme)
library(car)
library(tidyr)
library(latex2exp)

```

# Two Populations Means {#ch2pops}

## Learning Objectives for Chapter {#LearnObj8}

1. Compare two population means based on two samples
1. Determine if samples are paired or unpaired ("independent") when comparing two means
1. State the null and alternative hypothesis for a two sample t-test 
1. Calculate the sample averages and the difference of the sample averages
1. Perform an F-test of homogeneity of variance by calculating sample variances, and determine if you can "pool" the sample variances
1. Calculate the standard error of the difference
1. Describe the three cases for comparing two populations means and determine when each one is appropriate
1. Calculate the t-statistic and identify the appropriate critical t-value
1. After performing a two sample t test, sketch the t distribution, with the following parts labeled: 
      + the critical t value
      + the test statistic
      + the p value area under the curve.
      + the alpha level area under the curve. 
      + where the CI bounds would lie on the X axis (approximately)
1. Draw appropriate conclusions from a t test. In other words, interpret the results in terms of the original scientific question

## Two Populations 

We have learned in the previous chapters how to determine if a population mean is significantly different from a hypothetical population mean. However, researchers may want to know if two population means are significantly different from each other. For example, researchers might conduct an experiment comparing a fertilized field to an unfertilized field to determine a significant difference in yield, or an experiment comparing a high-carbohydrate diet to a high-protein diet to determine a significant difference in milk quality among cows. The researcher would take samples from each of the two treatment groups and test for a difference between the means to make inferences about the larger populations from which the samples were taken.  


```{block, type = 'stattip'}

##Steps to Test Two Population Means
<br> 

1. State the null and alternative hypotheses for the two populations

2. Collect samples from each population

3. Calculate the sample averages, $\bar{Y}_1$ and $\bar{Y}_2$, the difference of the averages,$\bar{d}$, and the sample variances, $s^2_1$ and $s^2_2$

4. If you do not know if the two population variances are equal, $\sigma_1 = \sigma_2$, perform an F-test to determine if you can pool the sample variances. 

5. Calculate the standard error of the difference, $s_{\bar{d}}$, between the two samples (**it is important to identify the appropriate Case equations to use in this step**)

6. Calculate the t-statistic using the calculated $\bar{d}$ and $s_{\bar{d}}$

7. Compare the calculated t-statistic to the critical t-value, and decide to reject or fail to reject the null hypothesis
```




## Hypothesis Testing

Before all the calculations have begun, it is important to understand the scientific question being asked. The purpose of testing two population means is to understand if there is a statistically significant difference between two populations or two treatment groups. Thus, our null  hypothesis and alternative hypothesis can be stated, respectively, as 

<br>

$$\text{ Null hypothesis: the mean of population 1 is equal to the mean of population 2, } \\
\text{ or there is no difference between the two population means } \\[15pt]
H_0 : \mu_1 = \mu_2 \quad \text{or} \quad \mu_{\bar{d}} = 0 \\[15pt]
\text{ Alternative hypothesis: the mean of population 1 is not equal to the mean of population 2, } \\
\text{ or there is a difference between the two population means } \\[15pt]
H_1 : \mu_1 \neq \mu_2 \quad \text{or}  \quad \mu_{\bar{d}} \neq 0$$

<br>

## Independent vs. Paired Samples

There are two different methods of sampling when comparing treatment means: **independent** samples and **paired**, or dependent samples. It is important to understand how the two populations are sampled to decide which equations are appropriate for the experiment. Using the wrong equations may lead to incorrect calculations and conclusions.  

### Independent Samples

Samples are considered **independent** when there is no relationship between the observations in one treatment group and the observations in the other treatment group, and the samples are randomly assigned to each treatment. For example, pigs are randomly assigned to two different diets to determine if they result in different mean body weights. In this case, we are interested in the difference between the two average weights resulting from each diet treatment. Since the pigs are randomly assigned to each diet, the assumption is that these samples (pigs) are independent of each other.  

<br>

```{r IndSamples, message=FALSE, warning=FALSE, paged.print=FALSE, out.width = '60%', fig.align='center', echo=FALSE, fig.cap ="Independent samples of eight pigs are randomly placed into two treatments.  Half of the eight pigs received treatment 1 and half of the eight pigs received treatment 2, where $r = 4$ is the number of samples per treatment, and $i = 1, 2, 3, 4$ is the sample number for a given treatment"}

knitr::include_graphics("images/CH8IndSamp.png")

```

<br>

### Paired Samples

Samples are considered **paired**, or dependent, when there is a relationship between the observations in one treatment and the observations in the other treatment. Paired samples are made from the direct comparisons of two measurements made on the same **experimental unit**. One situation in which individual pigs can be treated as the same experimental units is if two measurements are collected from the same individual. For example, before-and-after measurements on the same individuals are considered paired. To understand the effect of two different diets on pigs, an initial body weight measurement is collected from all pigs on a standard, high-carbohydrate diet, then following a set period of time on a high-protein diet, a second body weight measurement is taken from all pigs. In the paired sample case, we are interested in calculating the *average of the paired differences* between the two diet groups:

<br>
$$\bar{d} = \dfrac{\sum{d_i}}{r}$$ 
<br>

Contrast this with the independent sample case, where we are interested in the *difference between the averages* of the two groups.  

<br>
$$\bar{d} = \bar{x_1} - \bar{x_2}$$ 
<br>


```{r PairedMeasurements, message=FALSE, warning=FALSE, paged.print=FALSE, out.width = '60%', fig.align='center', echo=FALSE, fig.cap ="Paired samples of eight pigs under two treatments.  Each of the eight pigs has two measurements recorded for each treatment, where $r = 8$ is the number of samples per treatment, and $i = 1, 2, ..., 7, 8$ is the sample number for a given treatment"}

knitr::include_graphics("images/CH8PairSamp2Measurements.png")

```

<br>

In the above example, the samples were paired because the same individual pigs were used for each treatment. Paired sampling is not limited to before-and-after experiments on the same individuals, however. It can be extended to situations where there is some relationship or dependency between the replicates across treatment groups. For example, pigs that are from the same pen share genetic and environmental effects that are unique to that pen, and we can therefore treat the pens (and the pigs that come from them) as our experimental units. Imagine there are three different pig pens. From each pen, two pigs are randomly selected and assigned to different diets. The pigs that come from the same pen are "paired" and the differences between weights from each of the paired samples are measured. In this example, the experimental unit is not individual pigs but the pens that the pair of pigs come from. 

<br>

```{r PairedSamples, message=FALSE, warning=FALSE, paged.print=FALSE, out.width = '60%', fig.align='center', echo=FALSE, fig.cap ="Paired samples of pigs from the same pen under two treatments.  Only one pig from each of the three pens received treatment 1, while the remaining pig from each of the three pens recieved treatment 2. Each pig pen has two measurements recorded for each treatment, where r = 3 is the number of samples per treatment, and i = 1,2,3 is the sample number for a given treatment"}

knitr::include_graphics("images/CH8PairSamp.png")

```

<br>

## Equal vs. Unequal Variances

For independent samples, we must estimate the variances of both populations to calculate the standard error of the difference ($s^2_{\bar{d}}$), and perform a t test. We estimate the population variances ($\sigma_i^2$) from the sample variances ($s_i^2$). If the population variances are equal, we can pool the sample variances to obtain a better estimate of $\sigma_i^2$. To determine whether or not they are equal, we perform an F-test for equality of variances.

### F test for Equality of Variances.  

First, we state our null and alternative hypotheses for the F test:

<br> 

$$\text{Null hypothesis: the variance of population 1 is equal to the variance of population 2} $$
$$H_0 : \sigma_1^2 = \sigma_2^2 \\[25pt]$$

$$\text{Alternative hypothesis: the variance of population 1 is not equal to the variance of population 2} $$
$$H_1 : \sigma_1^2 \neq \sigma_2^2 $$
<br> 


To test for the equality of the population variances, we use a two-tailed F-test.  

<br>

```{r FCurve, message=FALSE, warning=FALSE, paged.print=FALSE, out.width = '60%', fig.align='center', echo=FALSE, fig.cap ="F-Distribution for determining the equality of variances (image from www.mtstatic.com)"}

knitr::include_graphics("images/CH8FCurve.png")

```

<br>

To calculate the F-ratio, we use the larger of the two sample variances ($s_1$) as the numerator, and the smaller of the two sample variances ($s_2$) as the denominator.

<br> 

$$F = \frac { \ s_1^2}{ \ s_2^2} \qquad \text{with}  \qquad df_{1} = r_{1} -1 , \ df_{2} = r_{2} -1$$

<br> 

This F-ratio can be compared to the critical F-value on the F-distribution table (Appendix XXX), given the degrees of freedom of the numerator and denominator. Since this is a two-tailed F-test, the $\alpha$ value to determine the critical F-value, $F_{crit}$, will be divided by two, $\frac{\alpha}{2}$.

The results of the F-test will help identify which case to use for calculating the standard error of the difference for our samples. 

If $F_{calc} > F_{crit, \frac{\alpha}{2}}$, then the null hypothesis, $H_0 : \sigma_1 = \sigma_2$, is rejected and the population variances are not equal.

If $F_{calc} < F_{crit, \frac{\alpha}{2}}$, then the null hypothesis, $H_0 : \sigma_1 = \sigma_2$, is not rejected and the population variances are assumed to be equal.

<br>

```{r FTestDec, message=FALSE, warning=FALSE, paged.print=FALSE, out.width = '60%', fig.align='center', echo=FALSE, fig.cap ="F-Test Decision Table from www.statistics4u.info"}

knitr::include_graphics("images/CH8FTestDec.png")

```

<br>

## Calculating the Standard Error of the Difference and the t-statistic

In the case of equal variances, the next step would be to calculate the pooled sample variance, $s^2$, which is the best estimate of $\sigma_i^2$. If the variances are unequal, then the best estimates of the population variances are the individual sample variances. We use the estimates of the population variances to calculate the standard error of the difference, $S_{\bar{d}}$. The $S_{\bar{d}}$, will be calculated differently depending on (1) if the samples are independent or paired, and in the case of independent samples, (2) if the population variances are equal or unequal, and (3) if the sample sizes are equal or unequal. Finally, we can use $S_{\bar{d}}$ to calculate the t-statistic, $t$ and perform the t-test, which is the final step to determine if the two populations means are significantly different from each other.  *We have previously used t-tests to evaluate if there is a significant difference between a population and a hypothetical population; now we can also use t-tests to evaluate if two populations are significantly different from each other.*

Note, for paired samples, the number of replicates, r, is equal to the number of pairs and the sample variance of the difference, $s^2_{d}$ is simply the variance of the paired differences.  

To appropriately identify which equations to use and when, there are three general "Case" scenarios.  

## Cases
### Case 1: Independent samples with equal population variances {#Case1}

When the two sample groups are independent and the two population variances are equal, then the two sample variances are estimates of the same population variance. To calculate a better estimate of the population variance, we can average the two sample variances to calculate the pooled sample variance $( s^2 )$ 

<br>

$$s^2 = \frac{({{s_1}^2})({r_1-1})+({{s_2}^2})({r_2-1})}{(r_1+r_2-2)} \qquad \text{with} \qquad df = r_1+r_2-2$$

<br> 

The standard error of the difference is then:

<br> 
$$\bar{d} = \bar{x_1} - \bar{x_2}$$ 
<br> 

When **the two sample sizes are equal**, the pooled variance and the standard error of the difference can more simply be calculated as

<br> 

$$s^2 = \frac{{{s_1}^2}+{{s_2}^2}}{2} \qquad \text{with} \qquad df = 2(r-1)$$

$$s_{\bar{d}} = \sqrt{\frac{{2s}^2}{r}}$$ 
<br> 

The test statistic can be calculated as:

$$t = \frac{\bar{d}-\mu_{\bar{d}}}{s_{\bar{d}}}$$
<br>

where,

$$\bar{d} = \bar{x_1} - \bar{x_2}$$ 

<br>

### Case 2: Independent samples with unequal population variances {#Case2}

When the population variances are unequal, we calculate the standard error of the difference using the two sample variances as our best estimates of the population variances.

<br> 

$$s_{\bar{d}} = \sqrt{\frac{{s_1}^2}{r_1}+\frac{{s_2}^2}{r_2}} \qquad \text{with}  \qquad df = r_1+r_2-2$$
<br> 

The test statistic is calculated as 

<br> 

$$t = \frac{\bar{d}-\mu_{\bar{d}}}{s_{\bar{d}}}$$
<br>

where,

$$\bar{d} = \bar{x_1} - \bar{x_2}$$ 
<br>

Since the population variances are unequal, we cannot use the Student's t-table to identify the critical t-value ($t_\alpha$).  The critical t-value is calculated instead as:

<br> 

$$t_\alpha = \frac{(t_1 s_{\bar{Y_1}}^2+t_2 s_{\bar{Y_2}}^2)}{(s_{\bar{Y_1}}^2+s_{\bar{Y_2}}^2)}$$
<br> 

where $t_1$ and $t_2$ are calculated with $r_1 -1$ and $r_2 -1$ degrees of freedom, respectively.

### Case 3: Paired samples {#Case3}

When observations are made on the same experimental unit (e.g., adjacent plots in the same field, pigs from the same pen, etc.) and are assigned to different treatments, they are considered **paired samples**. The average of paired differences, $\bar{d}$, the variance of the difference, $s_d^2$, the standard error of the difference, $s_\bar{d}$, and the test statistic, $t$, are calculated as follows:

<br> 

$$\bar{d} = \frac{\sum{d_i}}{r}$$

<br> 

$$s_d^2 = \frac{\sum(d_i-\bar{d})^2}{r-1} \qquad \text{with} \qquad  = r-1$$

<br> 

$$s_\bar{d} = (\frac{s_d^2}{r})^{1/2}$$

<br> 

$$t = \frac{(\bar{d}-\mu_{\bar{d}})}{s_{\bar{d}}}$$
<br> 

```{block}
### Two Populations Equation Summary


Table: (\#tab:CaseEquations) 

| Case | Pop Variances |  Sample Size  | Paired / Independent |                 Pooled Sample Variance                     |        Standard Error of the Difference           |      df     |          t-statistic          |         Confidence Interval     |
|-----:|:-------------:|:-------------:|:------------------:|:---------------------------------------------------------------:|:-------------------------------------------------:|:-----------:| :-------------------------------------------:|:----------------:|
|  1  |     Equal     |Equal/ Not Equal|    Independent      | $\frac{({{s_1}^2})({r_1-1})+({{s_2}^2})({r_2-1})}{(r_1+r_2-2)}$ |        $(\frac{s^2}{r_1 + r_2})^{1/2}$            | $r_1+r_2-2$ | $\frac{\bar{d}-\mu_{\bar{d}}}{s_{\bar{d}}}$  |   ${L\atop U} = \bar{d} \pm t_\alpha s_\bar{d}$   |
|  1  |     Equal     |     Equal     |     Independent      |              $\frac{{{s_1}^2}+{{s_2}^2}}{2}$                    |           $(\frac{{2S}^2}{r})^{1/2}$              |   $2(r-1)$  | $\frac{(\bar{d}-\mu_{\bar{d}})}{s_{\bar{d}}}$|   ${L\atop U} = \bar{d} \pm t_\alpha s_\bar{d}$   |
|  2  |   Not Equal   |Equal/ Not Equal|     Independent      |                                                                 | $(\frac{{s_1}^2}{r_1}+\frac{{s_2}^2}{r_2})^{1/2}$ | $r_1+r_2-2$ |  $\frac{\bar{d}-\mu_{\bar{d}}}{s_{\bar{d}}}$  |   ${L\atop U} = \bar{d} \pm t_\alpha s_\bar{d}$   |
|  3  |     Equal     |     Equal     |       Paired         |                          |            $(\frac{s_d^2}{r})^{1/2}$              |     $r-1$   | $\frac{(\bar{d}-\mu_{\bar{d}})}{s_{\bar{d}}}$|   ${L\atop U} = \bar{d} \pm t_\alpha s_\bar{d}$   |

```


## Confidence Intervals

After calculating the difference between the two sample averages ($\bar{d}$) and the standard error of the difference ($s_{\bar{d}}$), a confidence interval for the mean difference can be calculated to understand the level of confidence associated with the estimated mean difference. 

$${L\atop U} = \bar{d} \pm t_\alpha s_\bar{d}$$

Note that for Case 2, independent samples with unequal variances, you will need to calculate the critical t-value, however for Case 1 and 3 you can find this value on the Student's t-table (Appendix XXX) with the appropriate degrees of freedom (see appropriate Case for equation). Depending on which Case is used to calculate the standard error of the difference, the degrees of freedom to identify the critical t-value ($t_\alpha$) will vary when calculating your confidence intervals. 

## Decision to Reject or Fail to Reject the Null Hypothesis

After all of the steps and calculations, the calculated t-value and the critical t-value, $t_{\alpha}$, can be used in the final decision to reject or fail to reject the null hypothesis.  **The null hypothesis is never "accepted", rather the decision is to fail to reject.**  Remember, the null hypothesis when testing two population means is that the two populations are equal, $H_0 : \mu_1 = \mu_2 \ \ \text{or} \ \ \bar{d} = 0$

<br> 

$$\text{If} \ \ t > t_{\alpha} \ \text{and} \ P (t) < \alpha \ \text{then we reject the null hypothesis} $$  
$$\text{If} \ \ t < t_{\alpha} \ \text{and} \ P (t) > \alpha \ \text{then we fail to reject the null hypothesis}$$ 

<br> 

```{r DecisionMaking, message=FALSE, warning=FALSE, paged.print=FALSE, out.width = '60%', fig.align='center', echo=FALSE, fig.cap ="General Procedure for sampling two populations to make a final decision to reject or fail to reject the null hypothesis"}

knitr::include_graphics("images/CH8Strategy.png")


```
 
<br> 

## Bean Drought Example

Below is data collected on common bean plots that were randomly assigned to two different irrigation treatments: drought and normal irrigation. Yield data was collected from these plots and recorded in the table below.  
<br>



```{r BeanDrought, echo = FALSE, message=FALSE}

bean.yield <- data.frame(
  "Yield" = c("Yield 1", "Yield 2", "Yield 3", "Yield 4"), 
  "Drought" = c(590, 720, 720, 190 ), 
  "Irrigated" = c(2990, 2950, 2660, 2120))

knitr::kable(bean.yield, format = "html", caption = "Common bean yield (kg/ha) is measured under drought treatment and irrigation in Quilichao, Columbia (Sponchiado, 1985)")

```



### Stating the Hypotheses

This experiment features two treatments: drought and irrigated. The researchers aimed to identify if there was a significant difference in bean yield (kg/ha) between the two treatments. The null and alternative hypotheses can be stated, respectively, as 

<br> 

$$\text{Null hypothesis: the mean of the drought treatment is equal to the mean of the irrigated treatment,} \\ \text{ or there is no difference between drought and irrigated treatments on common bean yield} \\$$
$$\mu_1 = \mu_2   \quad  \text{or} \quad \mu_{\bar{d}} = 0$$
<br>

$$\text{Alternative hypothesis: the mean of the drought treatment is not equal to the mean of the irrigated treatment,} \\ \text{ or there is a difference between drought and irrigated treatments on common bean yield} \\$$
$$\mu_1 \neq \mu_2 \quad  \text{or} \quad \mu_{\bar{d}} \neq 0$$

<br> 

### Sampling Method

Since the samples were randomly assigned to the treatment and there was no additional information provided on how each sample was assigned to a given treatment, we can assume that the samples are independent of one another.  

### Calculating Sample Averages and the Mean Difference

As the calculations begin on the two treatments of this experiment, we will designate **sample 1 as the drought treatment and sample 2 as the irrigated treatment** to simplify labeling of our statistical terms. Be careful to maintain consistency of this designation throughout the complete set of calculations.  

Since the samples are independent, the averages of each sample are calculated as

\begin{equation}

\bar{Y}_1 = \frac{\sum Y_{i1}}{r_1} \\[20pt]
= \frac{590 + 720 + 720 + 190}{4} \\[20pt]
= 555 \\[25pt]
\bar{Y}_2 = \frac{\sum Y_{i2}}{r_2} \\[20pt]
= \frac{2990 + 2950 + 2660 + 2120}{4} \\[20pt]
= 2680

\end{equation}

<br> 

and the difference between the two averages is calculated as

<br> 

\begin{equation}

\bar{d} = \bar{Y}_2 - \bar{Y}_1 \\[20pt]
=  2680 - 555 \\[20pt]
= 2125

\end{equation}
<br>

We can do these calculations in R, as follows:
<br>
 
```{r, message=FALSE}
# the sum of the samples in each treatment
sum.Y1 <-  sum(bean.yield$Drought)
sum.Y2 <-  sum(bean.yield$Irrigated)

# the number of samples in each treatment
r1 <- length(bean.yield$Drought)
r2 <- length(bean.yield$Irrigated)

# calculate the sample averages by dividing the sample sums 
# by the number of samples for each treatment "by hand"
(Ybar1 <- sum.Y1 / r1)
(Ybar2 <- sum.Y2 / r2)

# a simpler method to calculate the sample averages
(Ybar1 <- mean(bean.yield$Drought))
(Ybar2 <- mean(bean.yield$Irrigated))

# calculate the average of the difference between the two treatments
(dbar <- Ybar2 - Ybar1)
```

<br> 

### Calculating Sample Variances

#### Calculate the Individual Sample Variances

Now, we need to determine if the population variances are equal. Information on the equality of the population variances may be provided for a given experiment.  However, in the absence of this information, the equality of the sample variances can be tested using an F test. First, we calculate each sample variance:

<br> 

\begin{equation}

s^2_1 = \frac{\sum (Y_{i1} - \bar{Y}_1)^2}{r_1 - 1} \\[20pt]
= \frac{(590 - 555)^2 + (720 - 555)^2 + (720-555)^2 + (190-555)^2}{4 - 1} \\[20pt]
= 62966.67 \\[25pt]

s^2_2 = \frac{\sum (Y_{i2} - \bar{Y}_2)^2}{r_2 - 1} \\[20pt]
= \frac{(2990 - 2680)^2 + (2950 - 2680)^2 + (2660 - 2680)^2 + (2120 - 2680)^2}{4 -1} \\[20pt]= 161000

\end{equation}
<br> 

```{r, message=FALSE}

# calculate the sample variances for each treatment "by hand"
(var1 <- sum((bean.yield$Drought - Ybar1)^2) / (r1 - 1))
(var2 <- sum((bean.yield$Irrigated - Ybar2)^2) / (r2 - 1))


# a simpler way to calculate the sample variances
(var1 <- var(bean.yield$Drought))
(var2 <- var(bean.yield$Irrigated))

# both methods yield the same answers
```


#### Using an F-test to determine if Population Variances are Equal

The F-test helps us determine if the population variances are equal. The null hypothesis is that the population variance of the drought treatment is equal to the population variance of the irrigated treatment.  If the population variances are equal, the two sample variances can be pooled to provide a more accurate estimate of the population variance.  

The calculated F-value is simply the ratio of the larger sample variance divided by the smaller sample variance

<br> 

$$F_{calc} = \frac{ \text{larger} \ s^2 }{\text{smaller} \ s^2} = \frac{161000}{62966.67} = 2.56$$
<br> 

```{r, message=FALSE}
# since var2 is greater than var1, var2 will be used 
# as the numerator and var1 will be used as the denominator 
Fcalc <- var2 / var1

```

Next, compare the calculated F-value, $F_{calc}$, to the critical F-value, $F_{crit}$, which can be found in F-Distribution Table. With $df_{numerator} = 3$, $df_{denominator} = 3$,  and $\alpha_{two-tailed} = \frac{0.05}{2}$, it is determined $F_{crit_\frac{\alpha}{2}} = 15.44$ and $F_{crit_\frac{1-\alpha}{2}} = 0.06$ 

```{r, message=FALSE}

# calculation of F-critical value using alpha = 0.05 /2 
# since the F-test is two-tailed, and the two degrees of freedom 
# for the numerator and denominator
alpha <- 0.05/2
(Fcrit.upper <- qf(alpha, r1-1, r2-1, lower.tail = FALSE))
(Fcrit.lower <- qf(alpha, r1-1, r2-1, lower.tail = TRUE))

```

Since the F-statistic falls within the two critical F-values, we fail to reject the null hypothesis that the two population variances are equal. 

<br> 

$$F_{calc} = 2.56 < F_{crit_\alpha} = 9.28$$ and 
$$F_{calc} = 2.56 > F_{crit_{1-\alpha}} = 0.11$$  

<br> 

Therefore, the population variances can be treated as equal and the sample variances can be pooled.  

<br>
```{r FDistInd, fig.cap = "F distribution for df1 = 3, df2 = 3, with the calculated F-ratio and the lower and upper F critical values shown from the bean drought example.", message=FALSE, echo = FALSE, warning=FALSE}
x <- seq(0.000001,16, 0.25)
pd <- df(x, df1 = 3, df2 = 3, ncp = 0)
plot(x, pd, 
     type = "l",
     xlab = "F-Value", ylab = "Probability Distribution", 
     main = "the F-Distribution Curve",
     lwd = 1.5)
abline(v = Fcrit.upper, 
       col = "chartreuse3", 
       lty = 3)
abline(v=Fcrit.lower,
       col = "chartreuse3",
       lty =3)
points(0.44, 0.57, pch = 4, col = "cornflowerblue")
text(1.5, 0.57, "F-calc", col = "cornflowerblue") 
text(1.4,0.05, "lower F-crit", col = "chartreuse3")
text(14,0.05, "upper F-crit", col = "chartreuse3")
text(8,0.25, "fail to reject H0")

```
<br>

#### Pooling Sample Variances

Since the F-test concluded that the two population variances are equal, the sample variances can be pooled to provide a more accurate estimate of the true variance.  

Since the two sample sizes are the same, $r_1 = 4$ and $r_2 = 4$, the following equation from Case 2 is used to pool the sample variances:

<br> 

\begin{equation}

s^2 = \frac{s_1^2 + s_2^2}{2} \\[20pt]
= \frac{62966.67 + 161000}{2} \\[20pt]
= 111983.33

\end{equation}
<br> 

```{r, message=FALSE}

# the pooled variance can be calculated by taking the average 
# of the two sample variances, since they have the same sample size
pooled.var <- ( var1 + var2 ) / 2

```
since our two sample sizes are equal, the degrees of freedom are 

<br> 

$$df = 2(r-1) = 6$$
<br> 

```{r, message=FALSE}

# Number of replicates in each bean yield treatment group
(r <- length(bean.yield$Yield))

# the degrees of freedom are calculated as
(df <- 2*(r-1))

```

### Calculating the Standard Error of the Difference

The standard error of the difference is calculated using the pooled variance $s^2$ and our sample size $r$, where $r_1 = r_2 = r$

<br> 

\begin{equation}

s_{\bar{d}} = \sqrt{ \frac{2s^2}{r\mathstrut}} \\[20pt]
=  \sqrt{\frac{2 \times  111983.33}{4\mathstrut}} \\[20pt]
= 236.63

\end{equation}

<br> 

```{r}
# the standard error of the difference is calculated by taking 
# the square root of 2 times the pooled variance,
# and dividing by the number of replicates, r

se.dbar <- sqrt( (2*pooled.var) / r)

```

### Calculating the t-statistic

The t-statistic is used to determine if we reject or fail to reject the null hypothesis that the population means are equal, $H_0: \mu_1 = \mu_2$ or that there is no difference between our population means, $H_0: \mu_{\bar{d}} = 0$.  

The t-statistic, $t_{calc}$, is calculated by using the difference of the averages, $\bar{d}$ and the standard error of the difference, $s_{\bar{d}}$.  


<br> 

\begin{equation}
t_{calc} = \frac{(\bar{d} -  \mu_{\bar{d}})}{s_{\bar{d}}} \\[20pt]
= \frac{2125 - 0}{236.63} \\[20pt]
= 8.98

\end{equation}
<br> 


$\mu_{\bar{d}} = 0$ because our null hypothesis is that there is no difference between the two population means, $H_0: \mu_{\bar{d}} = 0$  

We can do the same calculations in R:

```{r, message=FALSE}
# calculate the t-statistic by subtracting our hypothesized difference
# between the means, which is 0, from the sample difference, and 
# dividing by the standard error of the difference.
(t.calc <- ( dbar - 0 ) / se.dbar)

# a quicker method to calculate the t-statistic 
(t.test <- t.test(bean.yield$Irrigated, bean.yield$Drought,
                  alternative = "greater", paired = FALSE))

# both calculations yield the same value
```


We compare the calculated t-statistic to the critical t-value, $t_{crit}$, which can be found in the Student's t-Distribution Table. With the degrees of freedom of our pooled samples, $df = 2(r-1) = 6$, and $\alpha_{two-tailed} = \frac{0.05}{2}$, it is determined that $t_{crit} = 2.447$


Since $t_{calc} = 9.33 > t_{crit} = 2.447$, we reject the null hypothesis that there is no difference between the drought treatment and the irrigated treatment.   

```{r tBeanInd, warning = FALSE, echo = FALSE, fig.cap = "Student's t distribution for df = 6, with the calculated t value and the upper and lower t critical values from the bean drought example.", message=FALSE}
y <- seq(-6,10, 0.25)
pfd <- dt(y, df = 6, ncp = 0)
plot(y, pfd, 
     type = "l",
     xlab = "", ylab = "")
criticalt1 <- qt(p = 1 - 0.025, 
                df = 6)
criticalt2 <- qt(p = 0.025, 
                df = 6)
plot(y, pfd, 
     type = "l",
     xlab = "", ylab = "")
abline(v = criticalt1, 
       col = "chartreuse3", 
       lty = 3)
abline(v=criticalt2,
       col = "chartreuse3",
       lty =3)
points(8.98, 0.0001, pch = 4, col = "cornflowerblue")
text(8.98, 0.03, "t-calc", col = "cornflowerblue") 
text(-4,0.35, "lower t-crit", col = "chartreuse3")
text(4,0.35, "upper t-crit", col = "chartreuse3")
text(0,0.05, "fail to reject H0")
text(6,0.05, "reject H0")
```



## Bean Drought Example - Paired

Below is same data collected on common bean plots from the previous example.  *However, it is revealed that there are 4 unique varieties of common bean that were tested under both drought and normal irrigation*.  Yield data was collected from these plots and recorded in the table below.  
<br>


<br>

```{r BeanDroughtPaired, message =FALSE, echo = FALSE}
bean.paired <- data.frame(
  "Variety" = c("Var1", "Var2", "Var3", "Var4"), 
  "Drought" = c(590, 720, 720, 190), 
  "Irrigated" = c(2990, 2950, 2660, 2120))

knitr::kable(bean.paired, format = "html", caption = "Common bean yield (kg/ha) is measured under drought treatment and irrigation in four varieties in Quilichao, Columbia (Sponchiado, 1985).")
```



### Stating the Hypotheses

**Our null and alternative hypotheses will be the same as before**

$$\text{Null hypothesis: there is no difference between drought and irrigated treatments.} \\[15pt]$$

$$\mu_1 = \mu_2 \quad  \text{or} \quad \mu_{\bar{d}} = 0$$

$$\text{Alternative hypothesis: there is a difference between drought and irrigated treatments.}\\$$
$$\mu_1 \neq \mu_2 \quad  \text{or} \quad \mu_{\bar{d}} \neq 0$$


### Sampling Method

**The sampling method is now different**.  Since there are four known common bean varieties planted in both drought and irrigated treatments, each variety is considered an experimental unit and the samples are paired.   


### Calculating Sample Averages and the Average of the Difference


For paired samples, we take the difference of each experimental unit (i.e., each variety) between the two treatments, then take the average of the differences.

<br> 

\begin{equation}

\bar{d} =  \frac{\sum{d_i}}{r} \\[20pt]
=\frac{\sum|Y_{i2} - Y_{i1}|}{r} \\[20pt]
= \frac{|2990-590| + |2950 -720| + |2660-720| + |2120-190|}{4} \\[20pt]
= 2125

\end{equation}
<br> 

```{r, message = FALSE}
# create a new column of the difference between the drought 
# and irrigated treatment columns

bean.paired$d_i <-  bean.paired$Irrigated - bean.paired$Drought 

# calculate sum(d_i) by adding the column containing the differences 
# of the two treatments

sum.d_i <- sum(bean.paired$d_i)

# calculate r as the number of varieties (pairs of treatments)

r.pair <-  length(bean.paired$Variety)

# calculate d_bar

(dbar.pair <- sum.d_i / r.pair)

# alternatively:

mean(bean.paired$d_i)

```

### Calculating the Variance of the Difference

We do not need to calculate individual sample variances, since we will directly calculate the variance of the paired differences:

<br> 

\begin{equation}
s^2_{d} = \frac{\sum( d_i - \bar{d})^2}{r-1} \\[20pt]
= \frac{(2400-2125)^2 + (2230-2125)^2 + (1940-2125)^2 + (1930-2125)^2}{3} [20pt]
= 52966.67

\end{equation}
<br> 

```{r, message=FALSE}
# calculate the variance of the differences by summing the paired 
# differences and dividing by r - 1 

# var.d.pair = variance of the differences

(var.d.pair <- sum((bean.paired$d_i - dbar.pair) ^ 2) / (r.pair - 1))

# alternatively:

var(bean.paired$d_i)
```

### Calculating the Standard Error of the Difference

The standard error of the difference is calculated using the variance of the differences $s^2_d$ and our sample size $r$

<br> 

\begin{equation}
s_{\bar{d}} = \sqrt{\frac{s_d^2}{r}} \\[20pt]
= \sqrt{\frac{52966.67}{4}} \\[20pt]
= 115.07

\end{equation}

<br> 

```{r, message = FALSE}
# calculate the standard error of the difference by taking 
# the square root of the variance of the difference divided by r

se.dbar.pair <- sqrt(var.d.pair / r.pair)
```

### Calculating the t-statistic

The t-statistic is calculated using the same equation as in the independent sampling example

<br> 

\begin{equation}

t_{calc} = \frac{(\bar{d} -  \mu_{\bar{d}})}{s_{\bar{d}}} \\[20pt]
= \frac{2125 - 0}{115.07} \\[20pt]
= 18.47

\end{equation}
<br> 

```{r, message=FALSE}
# calculate the t-statistic by dividing the difference of the 
# averages by the standard error of the difference

t.calc.pair <- (dbar.pair - 0) / se.dbar.pair

# a simpler way to calculate the t-statistic

(t.test.pair <- t.test(bean.paired$Irrigated, bean.paired$Drought, 
                       alternative = "greater", paired = TRUE)) 

# Note, we specified "paired = TRUE" this time.
```

The calculated t-statistic is compared to the critical t-value, $t_{crit}$, which can be found in the Student's t-Distribution Table. With the degrees of freedom of our pooled samples, $df = r-1 = 3$, and $\alpha_{two-tailed} = \frac{0.05}{2}$, it is determined $t_{crit} = 3.182$

```{r, message = FALSE}
# we can calculate the critical t-value in r by using the qt() function and inputting alpha = 0.05
# and the df = r - 1.  Since this is a two-tailed t-test, alpha is
# divided by 2 for calculations

alpha <- 0.05

t.crit.pair <- qt(alpha / 2, df = r.pair -1, lower.tail = FALSE)
```

Since $t_{calc} = 18.47 > t_{crit} = 3.182$, we reject the null hypothesis that there is no difference between the drought treatment and the irrigated treatment.   

```{r tBeanDroughtPaired, fig.cap = "Student's t distribution for df = 3, with the calculated t value, and upper and lower critical t values for the paired bean drought example shown.", message=FALSE, echo = F}
z <- seq(-8,20, 0.25)
fd <- dt(z, df = 3, ncp = 0)
plot(z, fd, 
     type = "l",
     xlab = "", ylab = "")
criticalt3 <- qt(p = 1 - 0.025, 
                df = 3)
criticalt4 <- qt(p = 0.025, 
                df = 3)
plot(z, fd, 
     type = "l",
     xlab = "", ylab = "")
abline(v = criticalt3, 
       col = "chartreuse3", 
       lty = 3)
abline(v=criticalt4,
       col = "chartreuse3",
       lty =3)
points(18.47, 0.0001, pch = 4, col = "cornflowerblue")
text(18.47, 0.03, "t-calc", col = "cornflowerblue") 
text(-6,0.35, "lower t-crit", col = "chartreuse3")
text(6,0.35, "upper t-crit", col = "chartreuse3")
text(0,0.01, "fail to reject H0")
text(10,0.025, "reject H0")

```



## Exercises {#Ex8}

1. Another three samples have been submitted from the irrigation study on common bean; two samples for the irrigated treatment, and one sample for the drought treatment  
<br>

Table: (\#tab:BeanDrought) Common bean yield (kg/ha) is measured under drought treatment and irrigation in Quilichao, Columbia (Sponchiado, 1985) 

|   Treatment   |  Yield 1  |  Yield 2  |  Yield 3  |  Yield 4  |  Yield 5  |  Yield 6  |  
|--------------:|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|
|    Drought    |    590    |    720    |    720    |    190    |   1010    |           |  
|   Irrigated   |   2990    |   2950    |   2660    |   2120    |   1870    |   1560    |

<br>

Assuming these samples are independent of one another and are from the same bean variety, calculate the
 
* sample averages
* difference of the averages
* sample variances  
* difference of the sample variances
* t-statistic

2. Data is collected on the birth weight (lb) of calves at a single farm and grouped according to gender. The sample size, averages and standard deviation for each group is provided in the table below
  
<br>

Table: (\#tab:CalfBirthWeight) Average birth weight of calves (lb)

|   Gender   |   Calves  |    Mean   |    SD     | 
|-----------:|:---------:|:---------:|:---------:|
|    Male    |     30    |     60    |    10     |   
|   Female   |     25    |     50    |     7     | 

<br>

Is there a significant difference in the average birth weight of male and female calves, under the following conditions 
 
* the two populations have equal variances 
* the two populations have unequal variances
* the two populations have equal variances and equal sample sizes of 20
  
  
3. Data is collected on the average amount of protein in milk (g/cup) from dairy cows under two different diets

<br>

Table: (\#tab:MilkProtein) Average Protein Content (g/cup) in Milk

|      Diet      |   Cow 1   |    Cow 2  |   Cow 3   |   Cow 4   |   Cow 5   |   Cow 6   |   Cow 7   |
|---------------:|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|
|   High-Carb    |    7.56   |    8.04   |    7.14   |    7.68   |    7.8    |           |           |
|  High-Protein  |    7.86   |    8.04   |    7.68   |    8.1    |    7.98   |    7.62   |   7.44    |

<br>


Is there a significant difference in the average protein content for the two diets?

Is the average protein for the high-protein diet significantly greater than that for high-carbohydrate diet?

What is the 95% confidence interval of the difference between the sample averages?



## Homework : Two Population Means {#Hwk8}

### Walking Spiders

@wilder2004 examined the effect of praying mantis excrement on the behavior of wolf spiders to test whether cues from an introduced predator (the praying mantis) would change the movement rate of the native wolf spider. They put 15 wolf spiders in individual containers; inside each container there were two semicircles of filter paper. One semicircle was smeared with praying mantis excrement and one circle was without excrement. The researchers observed each spider for one hour and calculated spider mean walking speed while it moved across the excrement circle and the non-excrement circle. (Each of the 15 spiders was exposed to both treatments). Data were modified for the purpose of homework and are not the original true data.			

```{r}

walking.spiders <- data.frame(
  'Spider Number' = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15),
  'no excrement (cm/sec)' = c(2.5, 5.5, 1.1, 2.7, 2.8, 1.6, 3.2, 4.5, 5.0, 6.9, 2.2, 3.9, 3.8, 3.5, 5.7),
  'excrement (cm/sec)' = c(0.4, 1.9, 1.2, 2.6, 4.3, 0.3, 1.0, 1.5, 3.3, 2.6, 0.7, 1.4, 2.1, 3.4, 2.3),
  'difference' = c(2.1, 3.6, -0.1, 0.1, -1.5, 1.3, 2.2, 3.0, 1.7, 4.3, 1.5, 2.5, 1.7, 0.1, 3.4)) 

```
<br>

Table: (\#tab:WalkingSpiders) The mean walking speed of 15 wolf spiders inside a container in the presence and absence of praying mantis excrement.


| Spider Number   | no excrement (cm/sec) |  excrement (cm/sec)  |    difference    |
|----------------:|:---------------------:|:--------------------:|:----------------:|
|       1         |          2.5          |         0.4          |        2.1       |
|       2         |          5.5          |         1.9          |        3.6       |
|       3         |          1.1          |         1.2          |       -0.1       |
|       4         |          2.7          |         2.6          |        0.1       |
|       5         |          2.8          |         4.3          |       -1.5       |
|       6         |          1.6          |         0.3          |        1.3       |
|       7         |          3.2          |         1.0          |        2.2       |
|       8         |          4.5          |         1.5          |        3.0       |
|       9         |          5.0          |         3.3          |        1.7       |
|       10        |          6.9          |         2.6          |        4.3       |
|       11        |          2.2          |         0.7          |        1.5       |
|       12        |          3.9          |         1.4          |        2.5       |
|       13        |          3.8          |         2.1          |        1.7       |
|       14        |          3.5          |         3.4          |        0.1       |
|       15        |          5.7          |         2.3          |        3.4       |

<br>

1. Calculate the average speed and sample variance for each treatment.

2. Calculate the difference in speed between treatments for each spider. Report the average difference.

3. Calculate the sample variance for the difference between treatments.

4. Calculate the estimated variance of the averages of difference between treatments.

5. Is this a paired or independent sample case?

6. Calculate the t-value that corresponds to the observed difference.

7. Calculate the critical t value to determine if the difference is significant at the 5% level.

8. Calculate a 95% confidence interval for the difference between treatment means.

9. Can you conclude with 95% confidence that mean spider walking speed differed based on cue (praying mantis excrement)?


### Rat Life

@carlson1946 looked at the average lifespan of a rats based on gender. Below is lifespan (days) data from 14 male and 14 female rats, you may assume rat lifespan is distributed normally. Data were modified and are not the original true data. Assume variances are the same for males and females.	
```{r}

rat.life <- data.frame(
  'males' = c(700, 825, 425, 500, 575, 725, 800, 475, 575, 725, 500, 700, 575, 775),
  'females' = c(450, 725, 675, 725, 750, 850, 690, 725, 475, 700, 725, 475, 825, 725))

sample.avg <- sapply(rat.life, mean)

sample.var <- sapply(rat.life, var)

```

<br>

Table: (\#tab:InterSteps)

|   rat   |     males     |      females      |    
|--------:|:-------------:|:-----------------:|
|    1    |      700      |        450        |   
|    2    |      825      |        725        |  
|    3    |      425      |        675        |  
|    4    |      500      |        725        |  
|    5    |      575      |        750        |  
|    6    |      725      |        850        |  
|    7    |      800      |        690        |  
|    8    |      475      |        725        |  
|    9    |      575      |        475        |  
|    10   |      725      |        700        |  
|    11   |      500      |        725        |  
|    12   |      700      |        475        |  
|    13   |      575      |        825        |  
|    14   |      775      |        725        |  
|--------:|:-------------:|:-----------------:|
| average |     633.928   |       679.642     | 
|  s.var  |    17269.917  |      15571.016    | 

<br>

Test the hypothesis that lifespan does not differ between sexes.

10. Write the corresponding null and alternative hypothesis.

11. Assume homogeneous variance and calculate the pooled sample variance for rat lifespan.

12. Calculate the estimated variance of the difference between sample averages.

13. Calculate the t value to test for difference between sexes in lifespan. Subtract males from females.

14. Calculate the degrees of freedom of the t value.

15. Calculate the probability of observing a larger absolute value of t if Ho were true.

16. What do you conclude based on whether the calculated p is greater than alpha = 0.05.




## Laboratory Exercises  

### Plant Sciences {#Lab8PLS}

**Submit BOTH files for your lab report using the appropriate Canvas tool**

For each part and question below, type your code in the grey area below, between the sets of back-ticks (```) to perform the desired computation and get output. Type your answers below the corresponding grey area.

#### Part 1. Equality of variances [25 points]

Mass per mature seed (mg) of an invasive grass (medusahead, *Taeniatherum caput-medusae*) was measured when plants were grown in several randomly selected plots of perennial or annual grasses typical of the California Grasslands. The data are included in the R block below. 'A' stands for annual and 'P' for perennial.

Does the variance of seed mass differ between treatments (perennial vs. annual)? Perform a test of hypothesis at the 5% level ($\alpha = 0.05$) using the F-statistic. Look up the critical F value in Table A.7 and by using the qf(p = 0.05, df1 = , df2 = ) function.

Complete the calculations "by hand", using only basic R functions like var(). Then, use the var.test () R function to test for difference of variances.


```{r, eval=FALSE}
seedMassA <- c(5.02, 4.34, 4.17, 7.07, 5.92,
               5.33, 5.48, 4.59, 5.47, 5.88, 4.1,
               5.14, 4.98, 4.47, 4.26, 5.02,
               5.38, 5.3, 4.92, 4.96, 5.86, 6.65,
               5.23, 4.51, 5.41, 6.23, 5.96,
               5.12, 5.43, 4.98, 5.15, 5.81,
               6.14, 5.87, 6.16, 5.97, 6.39,
               6.25, 5.3, 5.43, 4.81, 4.76, 6.11,
               4.18, 5.59, 5.26, 5.23, 5.9, 6.27,
               5.31, 5.17, 4.93, 5.24, 4.96)

seedMassP <- c(4.9, 4.17, 4.47, 6.3, 4.52, 4.81,
               4.4, 2.98, 4.75, 5.17, 4.64, 4.7,
               5.13, 5.11, 5.33, 4.3, 4.24, 4.49,
               4.46, 5.06, 4.62, 5.58, 4.39,
               4.77, 5.18, 4.38, 4.76, 4.38,
               4.95, 5.71, 3.03, 4.2, 4.78, 5.04,
               4.76, 4.72, 4.87, 4.58, 4.69,
               4.27, 5.17, 4.93, 3.51, 5.11,
               5.38, 5.1, 3.2, 4.8, 4.17, 5.01,
               3.95, 5.62, 5.44, 3.7, 4.08, 4.36,
               4.68, 4.24)

(varA <- var(seedMassA))

(varP <- var(seedMassP))

# R function that does the complete test
var.test(seedMassA, seedMassP) 

(Fcalc <-              )

(r1 <- length(seedMassA))

(r2 <- length(         ))

(df1 <- r1 - 1)

(df2 <-       )

alpha <- 0.05

(Ftable <- qf(alpha, df1, df2, lower.tail = FALSE))

(p.of.Fcalc <- 2 * pf(Fcalc, df1, df2, lower.tail = FALSE))

# The probability is multiplied by 2 because the test is two-tailed.
```

ANSWER. Write the interpretation and conclusion from the test here:





#### Part 2. Difference between means with independent samples [30 points]

Calculate the 95% confidence interval for the difference between the mean mass per seed of plants grown in annual and perennial grass plots. *Ignore the possibility of using the z-approximation due to the large sample size and use the t distribution.*

a. Based on the results of the test of equality of variances, determine what case (SG pg. 88) applies and estimate the variance of the difference between averages. Then compute the confidence interval.

b. Perform a t-test of the null hypothesis that the mass per seed does not differ between plants grown in annual or perennial grass plots. Perform all calculations "by hand" and compare to the results from using the t.test() function.


```{r, eval=FALSE}

(varAP <- (df1 * varA + df2 * varP) / (df1 + df2))

varDbar <- varAP / r1 + 

(tcalc <- (mean(seedMassA) - mean(seedMassP)) /              )

(ttable <- qt(alpha / 2, df =          , lower.tail = FALSE)) # test is two-tailed

(CI.lo <- (mean(seedMassA) - mean(seedMassP)) - ttable * sqrt(varDbar))
(CI.hi <-                                                            )

(t.test.1 <- t.test(seedMassA, seedMassP, alternative = "two.sided", paired =      , var.equal =     )) # complete code

```

ANSWER. State the extremes of the confidence interval and interpret the result of the test of hypothesis here:







#### Part 3. Difference between means with paired samples [30 points]

Twelve plants were used in an experiment to study the effectiveness of using praying mantises to control aphid populations. Aphid density was measured before and after the addition of a mantis to the plant. Perform a test to determine if the mantis reduces aphid density. (Note that these are fictitious data and that the experimental design is simplified for teaching purposes. A real experiment should include a series of control plants to make sure that the potential change in aphid density is not due to other uncontrolled causes besides the addition of the mantis).


```{r, eval=FALSE}

aphids <- read.csv("Datasets/Aphids.txt", header = TRUE)

before <- aphids$before

after <- aphids$after

(t.test.2 <- t.test(before, after, alternative = "greater", paired =       )) # complete code

# repeat the test using "hand" calculations as in part 2 above. 
# Add lines of code below.

d <- after - before

var.d <- 

se.d.bar <- sqrt(var.d /            )

# since the denominator (r) represents the number of pairs, 
# and the number of individuals in the "before"" population is the same 
# as the number of individuals in the "after" population, 
# you could also use the code 
# se.d.bar <- sqrt(var.d / length(after))

dfs <- length(before) - 1

t.calc.d <- (mean(d) - 0) / se.d.bar

ttable <- qt(alpha / 2, df =     , lower.tail = FALSE)


```

ANSWER. Interpret the result of the test of hypothesis here:



#### Part 4: Paired or independent? [15 points]

For the following situations please determine if you should be conducting an independent or a paired t-test. Make sure to justify your answers!  In some of these situations multiple pieces of information are being collected so please indicate what groups/variables are being compared.

##### A. Aphids on soybeans

A researcher is interested in whether the presence of natural enemies significantly reduces herbivory from the invasive pest soybean aphid (*Aphis glycines*). She randomly chooses 36 individual soybean plants in 4 fields to measure. As a proxy for herbivory, she counts the number of soybean aphids on each plant. She then encloses half of the plants with a mesh exclusion cage, through which aphids can pass but large predatory insects cannot. After two weeks, she counts aphids on all 36 plants again, and determines the net change in aphid abundance under each treatment.

Answer here:



##### B. Compost for broccoli

A master gardener wants to know whether his decision to use organic compost instead of synthetic fertilizer is going to change the yield of his broccoli. To test this, he applies a consistent amount of fertilizer or compost to the soil in each of six plots in a random design (3 receive compost, 3 receive fertilizer). He then plants the same variety of broccoli in all plots and measures the average yield (grams of broccoli head per plant) at harvest for each treatment.

Answer here:




##### C. Habanero chili

You have developed a new cultivar of habanero chili (Capsicum chinense) that you have named "Screaming Siren". You are curious if the chilies produced at your breeding facility differ in spice from a colleague's farm in New Mexico. Both you and your colleague gather a sample of 10 random chilies and send the chilies to a lab to have their capsaicin, the compound in chilies that cause their piquancy, concentration measured. 

Answer here:




##### D. Fish oil and triglycerides

A medical research program is evaluating the efficacy of two natural ingredients, fish oil and niacin (vitamin B3), on blood triglyceride level. You wish to know if the ingredients differ in effect on blood triglycerides. Forty patients had their blood triglyceride levels measured before the experiment began. The forty patients were divided into two treatment groups of twenty patients. One treatment group received 4 grams of fish oil per day, the other received 1 gram of niacin per day.  After 30 days the patients had their blood triglyceride level measured.


Answer here:




##### E. Botanical composition after restoration

A researcher is interested in determining the difference in plant species composition after seeding with native perennial seeds. Before seeding they sample quadrats within the field at random to determine the initial plant species composition. At the end of the second growing season they sample quadrats within the field at random to determine the new plant species composition.

Answer here:




### Animal Sciences {#Lab8ANS}

**Submit BOTH files for your lab report using the appropriate Canvas tool**

For each part and question below, type your code in the grey area below, between the sets of back-ticks (```) to perform the desired computation and get output. Type your answers below the corresponding grey area.



#### Part 1 [25 points]

Milk production (lb), milk composition and body weights of UCD lactating dairy cows was collected in August of 2000. The cows are classified in two groups, Herd1 and Herd2, based on their genotype.

Does the variance of milk production differ between the two herds (Herd1 vs. Herd2)? Perform a test of hypothesis at the 5% level ($\alpha = 0.05$) using the F-statistic. Look up the critical F value in Table A.7 and by using the qf(p = 0.05, df1 = , df2 = ) function.

Complete the calculations "by hand", using only basic R functions like var(). Then, use the var.test () R function to test for difference of variances.

```{r,eval=FALSE}

library(readxl)
MilkData <- read.csv("Datasets/MilkEx5_data.csv")

herd1 <- subset(MilkData, HERD == 1)
milkherd1 <- herd1$TOTmilk
herd2 <- subset(MilkData, HERD == 2)
milkherd2 <- herd2$TOTmilk

## Test for the difference of variances "by hand"

# calculate the variance for each treatment (Herd1 and Herd2)
(var1 <- var(milkherd1))
(var2 <-               ) #complete code

# calculate the F-value for our treatments (the larger variance will always be the numerator)
(Fcalc <-              ) # complete code

# number of samples in each treatment
(r1 <- length(milkherd1))
(r2 <-                  ) #complete code

# degrees of freedom: number of samples - 1
(df1 <- r1 - 1)
(df2 <- r2 - 1)

alpha <- 0.05

# calculate the critical F-value (for our given alpha and degrees of freedom)
(Ftable <- qf(alpha, df1, df2, lower.tail = FALSE))

# Calculate the p-value of our treatment variances being equal 
# (the probability is multiplied by 2 because the test is two-tailed)
# complete the code to get the observed significance
(p.of.Fcalc <- 2 * pf(Fcalc, df1, df2, lower.tail = FALSE)) 


## R function that does the complete test
var.test(milkherd1, milkherd2) 
```

ANSWER 1.
Write the interpretation and conclusion from the test here:





#### Part 2 [30 points]

Calculate the 95% confidence interval for the difference between the milk production of dairy cows between the two herds. *Ignore the possibility of using the z-approximation due to the large sample size and use the t distribution.*

a. Based on the results of the test of equality of variances, determine what case (SG pg. 88) applies and estimate the variance of the difference between averages. Then compute the confidence interval.

b. Perform a t-test of the null hypothesis that milk production does not differ between diary cows from Herd1 and Herd2. Perform all calculations "by hand" and compare to the results from using the t.test() function.


```{r,eval=FALSE}
# Calculate the pooled variance of Herd1 and Herd2
(var12 <- (df1 * var1 + df2 * var2) / (df1 + df2))

# Calculate the difference in variances between Herd1 and Herd2
varDbar <- var12 / r1 + var12 / r2

# calculate the t-value for our treatments (Herd1 and Herd2)
(tcalc <- (mean(milkherd2) - mean(milkherd1)) /               ) #complete code

# calculate the critical t-value (for our given alpha and degrees of freedom) 
# complete code
(ttable <- qt(alpha / 2, df =           ,  lower.tail = FALSE)) # test is two-tailed

# calculate the bounds of the critical intervals
# for the difference between our two treatments
(CI.lo <- (mean(milkherd1) - mean(milkherd2)) - ttable * sqrt(varDbar))
(CI.hi <-                                                              ) #complete code


(t.test.herd <- t.test(milkherd1, milkherd2, alternative = "two.sided", paired = FALSE, var.equal = TRUE)) # complete code

```

ANSWER. State the extremes of the confidence interval and interpret the result of the test of hypothesis here:







#### Part 3 [30 points]

Milk production was measured in the morning (AM) and again in the evening (PM).  Perform a test to determine if there is a difference in milk production between the AM and PM. (Note that this is a paired t-test since the same sample of cows is being milk at two separate times).


```{r,eval=FALSE}
milkAM <- MilkData$AMmilk

milkPM <- MilkData$PMmilk

# repeat the test using "hand" calculations as in part 2 above. 
# Add lines of code below.

# difference between the means of milk treatments (AM vs PM)
d <- milkPM - milkAM

# difference between the variances of milk treatments
var.d <- var(d)

# standard error of the difference between milk treatments 
se.d.bar <- sqrt(var.d /             ) 
# complete code

# since the denominator (r) represents the number of pairs, and 
# the number of individuals in the "milkAM"
# population is the same as the number of
# individuals in the "milkPM" population, 
# you could also use the code 
# se.d.bar <- sqrt(var.d / length(milkPM))

dfs <- length(milkAM) - 1

# calculated t-value for the difference between milk treatments
t.calc.d <- (mean(d) - 0) /           
   #complete code

# critical t-value (for a given alpha and degrees of freedom)
ttable <- qt(alpha / 2, df =   , lower.tail = FALSE) 
# complete code


# complete missing code for t-test between milking times (AM vs PM)
(t.test.time <- t.test(milkPM, milkAM, alternative = "greater", paired =      )) 
```

ANSWER. Interpret the result of the test of hypothesis here:



#### Part 4: Paired or independent? [15 points]

For the following situations please determine if you should be conducting an independent or a paired t-test. Make sure to justify your answers!  In some of these situations multiple pieces of information are being collected so please indicate what groups/variables are being compared.

##### A. High protein diet

A researcher is interested in whether a high protein diet for dairy cows will significantly increase the protein content in milk. 36 dairy cows are randomly chosen in 4 fields to measure and the protein content of their milk is measured.  Half of the cows are chosen to receive a high protein diet and half recieve the standard diet.  After two weeks, protein content of milk production is measured again, and the change in protein content is calculated for each treatment.

Answer here:



##### B. Organic dairy feed

A researcher wants to know whether using organic diary feed will change the milk production of his cows. To test this, organic feed and non-organic feed is given to six cows of the same breed in a random design (3 receive organic feed, 3 receive non-organic feed) and dairy production is measured for each treatment.  


Answer here:




##### C. Cowabunga

You have developed a new breed of dairy cows that you have named "Cowabunga". You are curious if the milk produced from these cows at your facility in Davis differ in lactose content from a colleague's farm in Fresno. Both you and your colleague gather a sample of 10 random cows and send the milk to a lab to have their lactose content measured.  

Answer here:




##### D. Fish oil and blood triglycerides

A medical research program is evaluating the efficacy of two natural ingredients, fish oil and niacin (vitamin B3) on blood triglyceride level in diary cows.  You wish to know if the ingredients differ in effect on blood triglycerides. Forty cows had their blood triglyceride levels measured before the experiment began. The forty cows were divided into two treatment groups of twenty cows. One treatment group received 4 grams of fish oil per day, the other received 1 gram of niacin per day.  After 30 days the cows had their blood triglyceride level measured.  

Answer here:




##### E. Rumen flora

A researcher is interested in determining the difference in bacteria species composition in the rumen of a cow after changing the grazing location from one year to the next.  At the first grazing location, they sample gut bacteria within a herd at random to determine the initial rumen bacteria composition.  At the end of the year at the second grazing location they sample rumen bacteria within the herd at random to determine the new bacteria species composition.  

Answer here:





